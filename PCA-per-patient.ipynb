{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877f581e",
   "metadata": {
    "papermill": {
     "duration": 0.008833,
     "end_time": "2022-12-17T17:31:29.644259",
     "exception": false,
     "start_time": "2022-12-17T17:31:29.635426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Installation of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e1fe72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:31:29.662735Z",
     "iopub.status.busy": "2022-12-17T17:31:29.662096Z",
     "iopub.status.idle": "2022-12-17T17:34:17.290159Z",
     "shell.execute_reply": "2022-12-17T17:34:17.288711Z"
    },
    "papermill": {
     "duration": 167.640373,
     "end_time": "2022-12-17T17:34:17.293007",
     "exception": false,
     "start_time": "2022-12-17T17:31:29.652634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (22.1.2)\r\n",
      "Collecting pip\r\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 22.1.2\r\n",
      "    Uninstalling pip-22.1.2:\r\n",
      "      Successfully uninstalled pip-22.1.2\r\n",
      "Successfully installed pip-22.3.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (59.8.0)\r\n",
      "Collecting setuptools\r\n",
      "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (0.37.1)\r\n",
      "Collecting wheel\r\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\r\n",
      "Installing collected packages: wheel, setuptools\r\n",
      "  Attempting uninstall: wheel\r\n",
      "    Found existing installation: wheel 0.37.1\r\n",
      "    Uninstalling wheel-0.37.1:\r\n",
      "      Successfully uninstalled wheel-0.37.1\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 59.8.0\r\n",
      "    Uninstalling setuptools-59.8.0:\r\n",
      "      Successfully uninstalled setuptools-59.8.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "thinc 8.0.17 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.10.1 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "spacy 3.3.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "google-api-core 1.33.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "gcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2022.8.2 which is incompatible.\r\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.11 which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed setuptools-65.6.3 wheel-0.38.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\r\n",
      "Collecting torch==1.12+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.12.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (189.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.13.0+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.13.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (13.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchtext==0.13.0\r\n",
      "  Downloading torchtext-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.12+cpu) (4.4.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (9.1.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (2.28.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (1.21.6)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.13.0) (4.64.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (2.1.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (2022.9.24)\r\n",
      "Installing collected packages: torch, torchvision, torchtext\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0+cpu\r\n",
      "    Uninstalling torch-1.11.0+cpu:\r\n",
      "      Successfully uninstalled torch-1.11.0+cpu\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.12.0+cpu\r\n",
      "    Uninstalling torchvision-0.12.0+cpu:\r\n",
      "      Successfully uninstalled torchvision-0.12.0+cpu\r\n",
      "  Attempting uninstall: torchtext\r\n",
      "    Found existing installation: torchtext 0.12.0\r\n",
      "    Uninstalling torchtext-0.12.0:\r\n",
      "      Successfully uninstalled torchtext-0.12.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchaudio 0.11.0+cpu requires torch==1.11.0, but you have torch 1.12.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "allennlp 2.10.0 requires torch<1.12.0,>=1.10.0, but you have torch 1.12.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires torchvision<0.13.0,>=0.8.1, but you have torchvision 0.13.0+cpu which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0+cpu torchtext-0.13.0 torchvision-0.13.0+cpu\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting autogluon\r\n",
      "  Downloading autogluon-0.6.1-py3-none-any.whl (9.8 kB)\r\n",
      "Collecting autogluon.multimodal==0.6.1\r\n",
      "  Downloading autogluon.multimodal-0.6.1-py3-none-any.whl (289 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.7/289.7 kB\u001b[0m \u001b[31m515.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.core[all]==0.6.1\r\n",
      "  Downloading autogluon.core-0.6.1-py3-none-any.whl (226 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.6/226.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.timeseries[all]==0.6.1\r\n",
      "  Downloading autogluon.timeseries-0.6.1-py3-none-any.whl (103 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.features==0.6.1\r\n",
      "  Downloading autogluon.features-0.6.1-py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.vision==0.6.1\r\n",
      "  Downloading autogluon.vision-0.6.1-py3-none-any.whl (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.tabular[all]==0.6.1\r\n",
      "  Downloading autogluon.tabular-0.6.1-py3-none-any.whl (286 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.0/286.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.text==0.6.1\r\n",
      "  Downloading autogluon.text-0.6.1-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (2.28.1)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.24.93)\r\n",
      "Collecting dask<=2021.11.2,>=2021.09.1\r\n",
      "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.21 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.21.6)\r\n",
      "Collecting autogluon.common==0.6.1\r\n",
      "  Downloading autogluon.common-0.6.1-py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pandas!=1.4.0,<1.6,>=1.2.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.3.5)\r\n",
      "Requirement already satisfied: scipy<1.10.0,>=1.5.4 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.7.3)\r\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (4.64.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (3.5.3)\r\n",
      "Collecting distributed<=2021.11.2,>=2021.09.1\r\n",
      "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn<1.2,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.0.2)\r\n",
      "Requirement already satisfied: ray[tune]<2.1,>=2.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (2.0.0)\r\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (0.2.7)\r\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.features==0.6.1->autogluon) (5.9.1)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (3.7)\r\n",
      "Requirement already satisfied: defusedxml<=0.7.1,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.7.1)\r\n",
      "Collecting transformers<4.24.0,>=4.23.0\r\n",
      "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting seqeval<=1.2.2\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting omegaconf<2.2.0,>=2.1.1\r\n",
      "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: fairscale<=0.4.6,>=0.4.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.4.6)\r\n",
      "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.19.3)\r\n",
      "Collecting torchmetrics<0.9.0,>=0.8.0\r\n",
      "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pytorch-metric-learning<1.4.0,>=1.3.0\r\n",
      "  Downloading pytorch_metric_learning-1.3.2-py3-none-any.whl (109 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting Pillow<=9.4.0,>=9.3.0\r\n",
      "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: accelerate<0.14,>=0.9 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.12.0)\r\n",
      "Requirement already satisfied: pytorch-lightning<1.8.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (1.7.7)\r\n",
      "Collecting evaluate<=0.3.0\r\n",
      "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<=4.8.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (4.6.1)\r\n",
      "Requirement already satisfied: smart-open<5.3.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (5.2.1)\r\n",
      "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.95 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.1.97)\r\n",
      "Collecting nlpaug<=1.1.10,>=1.1.10\r\n",
      "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.8/410.8 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting timm<0.7.0\r\n",
      "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nptyping<1.5.0,>=1.4.4\r\n",
      "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\r\n",
      "Collecting openmim<=0.2.1,>0.1.5\r\n",
      "  Downloading openmim-0.2.1-py2.py3-none-any.whl (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: text-unidecode<=1.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (1.3)\r\n",
      "Requirement already satisfied: torchtext<0.14.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.13.0)\r\n",
      "Requirement already satisfied: torchvision<0.14.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.13.0+cpu)\r\n",
      "Requirement already satisfied: torch<1.13,>=1.9 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (1.12.0+cpu)\r\n",
      "Collecting albumentations<=1.2.0,>=1.1.0\r\n",
      "  Downloading albumentations-1.2.0-py3-none-any.whl (113 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (2.5)\r\n",
      "Requirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (2.7.9)\r\n",
      "Requirement already satisfied: lightgbm<3.4,>=3.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (3.3.2)\r\n",
      "Requirement already satisfied: catboost<1.2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (1.1)\r\n",
      "Requirement already satisfied: xgboost<1.8,>=1.6 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (1.6.2)\r\n",
      "Collecting psutil<6,>=5.7.3\r\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting gluonts~=0.11.0\r\n",
      "  Downloading gluonts-0.11.5-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting joblib~=1.1\r\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: statsmodels~=0.13.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.timeseries[all]==0.6.1->autogluon) (0.13.2)\r\n",
      "Collecting sktime<0.14,>=0.13.1\r\n",
      "  Downloading sktime-0.13.4-py3-none-any.whl (7.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pmdarima~=1.8.2\r\n",
      "  Downloading pmdarima-1.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tbats~=1.1\r\n",
      "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m93.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: gluoncv<0.10.6,>=0.10.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.vision==0.6.1->autogluon) (0.10.5.post0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from autogluon.common==0.6.1->autogluon.core[all]==0.6.1->autogluon) (65.6.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->autogluon) (21.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->autogluon) (6.0)\r\n",
      "Collecting albumentations<=1.2.0,>=1.1.0\r\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.1->autogluon) (4.5.4.60)\r\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.1->autogluon) (0.0.4)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (5.10.0)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (0.8.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (1.15.0)\r\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2022.8.2)\r\n",
      "Requirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (0.11.2)\r\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.1.0)\r\n",
      "Requirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.7.0)\r\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.0.4)\r\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.4.0)\r\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (8.0.4)\r\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (6.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (3.1.2)\r\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.2.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (4.13.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.70.13)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.3.5.1)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (2.1.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (3.0.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.10.1)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.18.0)\r\n",
      "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.5.27)\r\n",
      "Requirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.3.1)\r\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (22.3.1)\r\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.0.7)\r\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.0.3)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (2.6.0)\r\n",
      "Requirement already satisfied: autocfg in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (0.0.8)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (4.5.4.60)\r\n",
      "Requirement already satisfied: yacs in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (0.1.8)\r\n",
      "Requirement already satisfied: pydantic~=1.7 in /opt/conda/lib/python3.7/site-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.1->autogluon) (1.8.2)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.7/site-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.1->autogluon) (4.4.0)\r\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.7/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.1->autogluon) (0.10.9.7)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.1->autogluon) (0.18.2)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (21.4.0)\r\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (5.8.0)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (0.18.1)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.6.1->autogluon) (0.38.4)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx<3.0,>=2.3->autogluon.tabular[all]==0.6.1->autogluon) (5.1.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.6.1->autogluon) (2021.11.10)\r\n",
      "Collecting typish>=1.7.0\r\n",
      "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\r\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting model-index\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (0.4.5)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.7/site-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (12.1.0)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (0.9.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->autogluon) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->autogluon) (2022.1)\r\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /opt/conda/lib/python3.7/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.1->autogluon) (0.29.32)\r\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.1->autogluon) (1.26.12)\r\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (2.10.1)\r\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.3.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (3.7.1)\r\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /opt/conda/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (3.19.4)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: virtualenv in /opt/conda/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (20.15.1)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.2.0)\r\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /opt/conda/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.43.0)\r\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (2.5.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (2.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (3.3)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->autogluon) (2021.11.2)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->autogluon) (2.19.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2,>=1.0.0->autogluon.core[all]==0.6.1->autogluon) (3.1.0)\r\n",
      "Collecting deprecated>=1.2.13\r\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Requirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.7/site-packages (from sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (0.55.2)\r\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels~=0.13.0->autogluon.timeseries[all]==0.6.1->autogluon) (0.5.2)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<4.24.0,>=4.23.0->autogluon.multimodal==0.6.1->autogluon) (0.12.1)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (1.0.1)\r\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.93 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (1.27.93)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (0.6.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (4.33.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (1.4.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (3.0.9)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (0.11.0)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (8.0.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (3.8.1)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.13->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (1.12.1)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (3.8.0)\r\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.53->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (0.38.1)\r\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.0.0)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.0.8)\r\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.6.2)\r\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.4.2)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.10.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.0.10)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.7.9)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.0.3)\r\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (8.0.17)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (2.4.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.0.9)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.3.0)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (2.0.8)\r\n",
      "Collecting typing-extensions~=4.0\r\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (2.0.7)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.15.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (2.2.2)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (1.8.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.6.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (3.3.7)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (1.35.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.4.6)\r\n",
      "Requirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.1.1)\r\n",
      "Collecting ordered-set\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (8.0.1)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich->openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (2.12.0)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from rich->openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (0.9.1)\r\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from virtualenv->ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (0.3.4)\r\n",
      "Requirement already satisfied: platformdirs<3,>=2 in /opt/conda/lib/python3.7/site-packages (from virtualenv->ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (2.5.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (4.0.2)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (6.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (1.7.2)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.13.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (4.8)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.2.7)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (4.2.4)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (1.3.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (3.2.0)\r\n",
      "Building wheels for collected packages: antlr4-python3-runtime, seqeval\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=96eaf56a356bea38db5a4a584b191be1cba4b86967e883d433baa000d425be18\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/ef/75/1b8c6588a8a8a15d5a9136608a9d65172a226577e7ae89da31\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=1f77aaa005d8e48f7cad01f62990d781f7b53449497f2826d8db5ffacb5a9159\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b2/a1/b7/0d3b008d0c77cd57332d724b92cf7650b4185b493dc785f00a\r\n",
      "Successfully built antlr4-python3-runtime seqeval\r\n",
      "Installing collected packages: typish, antlr4-python3-runtime, typing-extensions, psutil, Pillow, ordered-set, omegaconf, nptyping, joblib, deprecated, dask, torchmetrics, seqeval, nlpaug, gluonts, transformers, timm, sktime, pytorch-metric-learning, pmdarima, model-index, distributed, albumentations, tbats, openmim, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.vision, autogluon.timeseries, autogluon.text, autogluon\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.4.0\r\n",
      "    Uninstalling typing_extensions-4.4.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.4.0\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 5.9.1\r\n",
      "    Uninstalling psutil-5.9.1:\r\n",
      "      Successfully uninstalled psutil-5.9.1\r\n",
      "  Attempting uninstall: Pillow\r\n",
      "    Found existing installation: Pillow 9.1.1\r\n",
      "    Uninstalling Pillow-9.1.1:\r\n",
      "      Successfully uninstalled Pillow-9.1.1\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.0.1\r\n",
      "    Uninstalling joblib-1.0.1:\r\n",
      "      Successfully uninstalled joblib-1.0.1\r\n",
      "  Attempting uninstall: dask\r\n",
      "    Found existing installation: dask 2022.2.0\r\n",
      "    Uninstalling dask-2022.2.0:\r\n",
      "      Successfully uninstalled dask-2022.2.0\r\n",
      "  Attempting uninstall: torchmetrics\r\n",
      "    Found existing installation: torchmetrics 0.10.0\r\n",
      "    Uninstalling torchmetrics-0.10.0:\r\n",
      "      Successfully uninstalled torchmetrics-0.10.0\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "  Attempting uninstall: distributed\r\n",
      "    Found existing installation: distributed 2022.2.0\r\n",
      "    Uninstalling distributed-2022.2.0:\r\n",
      "      Successfully uninstalled distributed-2022.2.0\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.3.0\r\n",
      "    Uninstalling albumentations-1.3.0:\r\n",
      "      Successfully uninstalled albumentations-1.3.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.10.1 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.1.1 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\r\n",
      "pandas-profiling 3.1.0 requires joblib~=1.0.1, but you have joblib 1.2.0 which is incompatible.\r\n",
      "pandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\r\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "allennlp 2.10.0 requires torch<1.12.0,>=1.10.0, but you have torch 1.12.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires torchvision<0.13.0,>=0.8.1, but you have torchvision 0.13.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires transformers<4.21,>=4.1, but you have transformers 4.23.1 which is incompatible.\r\n",
      "aiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.27.93 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed Pillow-9.3.0 albumentations-1.1.0 antlr4-python3-runtime-4.8 autogluon-0.6.1 autogluon.common-0.6.1 autogluon.core-0.6.1 autogluon.features-0.6.1 autogluon.multimodal-0.6.1 autogluon.tabular-0.6.1 autogluon.text-0.6.1 autogluon.timeseries-0.6.1 autogluon.vision-0.6.1 dask-2021.11.2 deprecated-1.2.13 distributed-2021.11.2 evaluate-0.3.0 gluonts-0.11.5 joblib-1.2.0 model-index-0.1.11 nlpaug-1.1.10 nptyping-1.4.4 omegaconf-2.1.2 openmim-0.2.1 ordered-set-4.1.0 pmdarima-1.8.5 psutil-5.8.0 pytorch-metric-learning-1.3.2 seqeval-1.2.2 sktime-0.13.4 tbats-1.1.2 timm-0.6.12 torchmetrics-0.8.2 transformers-4.23.1 typing-extensions-4.1.1 typish-1.9.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Installation of AutoGluon\n",
    "!pip3 install -U pip\n",
    "!pip3 install -U setuptools wheel\n",
    "!pip3 install torch==1.12+cpu torchvision==0.13.0+cpu torchtext==0.13.0 -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "!pip3 install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5a04a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:34:17.378708Z",
     "iopub.status.busy": "2022-12-17T17:34:17.378275Z",
     "iopub.status.idle": "2022-12-17T17:34:17.388505Z",
     "shell.execute_reply": "2022-12-17T17:34:17.387517Z"
    },
    "papermill": {
     "duration": 0.055717,
     "end_time": "2022-12-17T17:34:17.390762",
     "exception": false,
     "start_time": "2022-12-17T17:34:17.335045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restating the kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902661a5",
   "metadata": {
    "papermill": {
     "duration": 0.041767,
     "end_time": "2022-12-17T17:34:17.474186",
     "exception": false,
     "start_time": "2022-12-17T17:34:17.432419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Importation of packages and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92c829b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:34:17.561466Z",
     "iopub.status.busy": "2022-12-17T17:34:17.561103Z",
     "iopub.status.idle": "2022-12-17T17:34:19.110522Z",
     "shell.execute_reply": "2022-12-17T17:34:19.108656Z"
    },
    "papermill": {
     "duration": 1.595681,
     "end_time": "2022-12-17T17:34:19.112687",
     "exception": false,
     "start_time": "2022-12-17T17:34:17.517006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/open-problems-multimodal/sample_submission.csv\n",
      "/kaggle/input/open-problems-multimodal/train_cite_targets.h5\n",
      "/kaggle/input/open-problems-multimodal/metadata_cite_day_2_donor_27678.csv\n",
      "/kaggle/input/open-problems-multimodal/test_multi_inputs.h5\n",
      "/kaggle/input/open-problems-multimodal/evaluation_ids.csv\n",
      "/kaggle/input/open-problems-multimodal/train_cite_inputs.h5\n",
      "/kaggle/input/open-problems-multimodal/train_multi_targets.h5\n",
      "/kaggle/input/open-problems-multimodal/train_multi_inputs.h5\n",
      "/kaggle/input/open-problems-multimodal/metadata.csv\n",
      "/kaggle/input/open-problems-multimodal/test_cite_inputs_day_2_donor_27678.h5\n",
      "/kaggle/input/open-problems-multimodal/test_cite_inputs.h5\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import autogluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Import files from Kaggle\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d314f",
   "metadata": {
    "papermill": {
     "duration": 0.043523,
     "end_time": "2022-12-17T17:34:19.198801",
     "exception": false,
     "start_time": "2022-12-17T17:34:19.155278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Opening files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25600d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:34:19.284506Z",
     "iopub.status.busy": "2022-12-17T17:34:19.283535Z",
     "iopub.status.idle": "2022-12-17T17:35:13.721594Z",
     "shell.execute_reply": "2022-12-17T17:35:13.718160Z"
    },
    "papermill": {
     "duration": 54.488737,
     "end_time": "2022-12-17T17:35:13.728924",
     "exception": false,
     "start_time": "2022-12-17T17:34:19.240187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features = pd.read_hdf(\"/kaggle/input/open-problems-multimodal/train_cite_inputs.h5\")#features_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38d34ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:35:13.822692Z",
     "iopub.status.busy": "2022-12-17T17:35:13.821791Z",
     "iopub.status.idle": "2022-12-17T17:35:14.493971Z",
     "shell.execute_reply": "2022-12-17T17:35:14.492987Z"
    },
    "papermill": {
     "duration": 0.721653,
     "end_time": "2022-12-17T17:35:14.497077",
     "exception": false,
     "start_time": "2022-12-17T17:35:13.775424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_target = pd.read_hdf(\"/kaggle/input/open-problems-multimodal/train_cite_targets.h5\")#target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de8d9e",
   "metadata": {
    "papermill": {
     "duration": 0.043769,
     "end_time": "2022-12-17T17:35:14.587867",
     "exception": false,
     "start_time": "2022-12-17T17:35:14.544098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc8331",
   "metadata": {
    "papermill": {
     "duration": 0.046445,
     "end_time": "2022-12-17T17:35:14.681603",
     "exception": false,
     "start_time": "2022-12-17T17:35:14.635158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1. Removing the columns with only 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1a3f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:35:14.771856Z",
     "iopub.status.busy": "2022-12-17T17:35:14.771451Z",
     "iopub.status.idle": "2022-12-17T17:35:32.878271Z",
     "shell.execute_reply": "2022-12-17T17:35:32.876903Z"
    },
    "papermill": {
     "duration": 18.158449,
     "end_time": "2022-12-17T17:35:32.883194",
     "exception": false,
     "start_time": "2022-12-17T17:35:14.724745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features.loc['Total']= df_features.sum()\n",
    "unwanted = [column for column in df_features.columns \n",
    "            if df_features[column][\"Total\"]==0]\n",
    "df_features.drop(unwanted, axis=1, inplace=True)\n",
    "df_features.drop(\"Total\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e225d",
   "metadata": {
    "papermill": {
     "duration": 0.042862,
     "end_time": "2022-12-17T17:35:32.973272",
     "exception": false,
     "start_time": "2022-12-17T17:35:32.930410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2. Finding the genes directly linked to the target protein levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df440af",
   "metadata": {
    "papermill": {
     "duration": 0.042708,
     "end_time": "2022-12-17T17:35:33.058344",
     "exception": false,
     "start_time": "2022-12-17T17:35:33.015636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We use naming conventions to find the genes directly linked to our targeted protein levels by finding in each gene if the name of the protein is contained in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fcea43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:35:33.146538Z",
     "iopub.status.busy": "2022-12-17T17:35:33.145817Z",
     "iopub.status.idle": "2022-12-17T17:35:33.719600Z",
     "shell.execute_reply": "2022-12-17T17:35:33.718328Z"
    },
    "papermill": {
     "duration": 0.621378,
     "end_time": "2022-12-17T17:35:33.722748",
     "exception": false,
     "start_time": "2022-12-17T17:35:33.101370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for protein in df_target.columns:\n",
    "    for gene in df_features.columns:\n",
    "        if protein in gene:\n",
    "            features_list.append(gene)\n",
    "features_list = np.unique(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd34917",
   "metadata": {
    "papermill": {
     "duration": 0.041986,
     "end_time": "2022-12-17T17:35:33.807418",
     "exception": false,
     "start_time": "2022-12-17T17:35:33.765432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3. Performing PCA on the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48de39a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:35:33.893998Z",
     "iopub.status.busy": "2022-12-17T17:35:33.893296Z",
     "iopub.status.idle": "2022-12-17T17:35:35.735721Z",
     "shell.execute_reply": "2022-12-17T17:35:35.734710Z"
    },
    "papermill": {
     "duration": 1.889688,
     "end_time": "2022-12-17T17:35:35.738652",
     "exception": false,
     "start_time": "2022-12-17T17:35:33.848964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Spliting the training set into two: the genes directly linked to our proteins and the others\n",
    "df_to_pca = df_features.drop(features_list, axis=1)\n",
    "df_features = df_features[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710ec67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:35:35.828483Z",
     "iopub.status.busy": "2022-12-17T17:35:35.828085Z",
     "iopub.status.idle": "2022-12-17T17:35:35.833192Z",
     "shell.execute_reply": "2022-12-17T17:35:35.831964Z"
    },
    "papermill": {
     "duration": 0.053064,
     "end_time": "2022-12-17T17:35:35.835541",
     "exception": false,
     "start_time": "2022-12-17T17:35:35.782477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "x = df_to_pca.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b44ce40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:35:35.924998Z",
     "iopub.status.busy": "2022-12-17T17:35:35.924617Z",
     "iopub.status.idle": "2022-12-17T17:39:19.336178Z",
     "shell.execute_reply": "2022-12-17T17:39:19.334305Z"
    },
    "papermill": {
     "duration": 223.461289,
     "end_time": "2022-12-17T17:39:19.340159",
     "exception": false,
     "start_time": "2022-12-17T17:35:35.878870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Performing PCA and keeping the 500 biggest components\n",
    "pca = PCA(n_components=500)\n",
    "principalComponents = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a81915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:39:19.428470Z",
     "iopub.status.busy": "2022-12-17T17:39:19.427965Z",
     "iopub.status.idle": "2022-12-17T17:39:19.764477Z",
     "shell.execute_reply": "2022-12-17T17:39:19.763378Z"
    },
    "papermill": {
     "duration": 0.382999,
     "end_time": "2022-12-17T17:39:19.767080",
     "exception": false,
     "start_time": "2022-12-17T17:39:19.384081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating a new features dataframe using PCA and our directly-linked genes\n",
    "df_features = df_features.join(pd.DataFrame(data=principalComponents, index=df_features.index), on=\"cell_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5403cf53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:39:19.853995Z",
     "iopub.status.busy": "2022-12-17T17:39:19.852950Z",
     "iopub.status.idle": "2022-12-17T17:39:20.021416Z",
     "shell.execute_reply": "2022-12-17T17:39:20.020293Z"
    },
    "papermill": {
     "duration": 0.214165,
     "end_time": "2022-12-17T17:39:20.023727",
     "exception": false,
     "start_time": "2022-12-17T17:39:19.809562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimizing the RAM by removing useless variables\n",
    "del pca, df_to_pca, x, principalComponents\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d845c9",
   "metadata": {
    "papermill": {
     "duration": 0.042963,
     "end_time": "2022-12-17T17:39:20.109672",
     "exception": false,
     "start_time": "2022-12-17T17:39:20.066709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4. Creating the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d948f736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:39:20.197137Z",
     "iopub.status.busy": "2022-12-17T17:39:20.196730Z",
     "iopub.status.idle": "2022-12-17T17:39:21.348115Z",
     "shell.execute_reply": "2022-12-17T17:39:21.347122Z"
    },
    "papermill": {
     "duration": 1.198669,
     "end_time": "2022-12-17T17:39:21.350875",
     "exception": false,
     "start_time": "2022-12-17T17:39:20.152206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"/kaggle/input/open-problems-multimodal/metadata.csv\")#reading the metadata file \n",
    "metadata = metadata[metadata[\"cell_id\"].isin(df_features.index)].drop([\"technology\"], axis=1)#keeping the metadata of our citeSeq data and droping useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65dda6ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:39:21.437258Z",
     "iopub.status.busy": "2022-12-17T17:39:21.436650Z",
     "iopub.status.idle": "2022-12-17T17:39:22.597985Z",
     "shell.execute_reply": "2022-12-17T17:39:22.596734Z"
    },
    "papermill": {
     "duration": 1.207358,
     "end_time": "2022-12-17T17:39:22.600376",
     "exception": false,
     "start_time": "2022-12-17T17:39:21.393018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the train and test dataset based on the dates. Splting on a 80/20 split and keeping the days 2/3 and a part of day 4 on the train set and tesing on the rest.\n",
    "df_autogluon = metadata.join(df_features, on=\"cell_id\").join(df_target, on=\"cell_id\")\n",
    "df_autogluon_train_1 = df_autogluon[df_autogluon[\"day\"]<4]\n",
    "df_autogluon_day_4 = df_autogluon[df_autogluon[\"day\"]==4]\n",
    "df_autogluon_train_2 = df_autogluon_day_4.sample(n = int(df_autogluon.shape[0]*0.80 - df_autogluon_train_1.shape[0]), random_state=4)\n",
    "df_autogluon_test = df_autogluon_day_4.drop(df_autogluon_train_2.index)\n",
    "\n",
    "del df_autogluon, df_autogluon_day_4\n",
    "gc.collect()\n",
    "\n",
    "df_autogluon_train = pd.concat([df_autogluon_train_1, df_autogluon_train_2])\n",
    "\n",
    "del df_autogluon_train_1, df_autogluon_train_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d927f5",
   "metadata": {
    "papermill": {
     "duration": 0.042261,
     "end_time": "2022-12-17T17:39:22.685803",
     "exception": false,
     "start_time": "2022-12-17T17:39:22.643542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Creation of the models using AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b897cd3",
   "metadata": {
    "papermill": {
     "duration": 0.04208,
     "end_time": "2022-12-17T17:39:22.770787",
     "exception": false,
     "start_time": "2022-12-17T17:39:22.728707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.1. The scoring function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9041a94",
   "metadata": {
    "papermill": {
     "duration": 0.04212,
     "end_time": "2022-12-17T17:39:22.855419",
     "exception": false,
     "start_time": "2022-12-17T17:39:22.813299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The competition had a special metric: for every row, it computes the Pearson correlation between y_true and y_pred, and then all these correlation coefficients are averaged.\n",
    "\n",
    "In order to compare our results with other competitors, we use the same metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401fe8e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:39:22.962119Z",
     "iopub.status.busy": "2022-12-17T17:39:22.961114Z",
     "iopub.status.idle": "2022-12-17T17:39:22.971145Z",
     "shell.execute_reply": "2022-12-17T17:39:22.969934Z"
    },
    "papermill": {
     "duration": 0.064725,
     "end_time": "2022-12-17T17:39:22.973423",
     "exception": false,
     "start_time": "2022-12-17T17:39:22.908698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c696e",
   "metadata": {
    "papermill": {
     "duration": 0.049421,
     "end_time": "2022-12-17T17:39:23.066728",
     "exception": false,
     "start_time": "2022-12-17T17:39:23.017307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.2. Model training and testing per donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0cdeab1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:39:23.154313Z",
     "iopub.status.busy": "2022-12-17T17:39:23.153930Z",
     "iopub.status.idle": "2022-12-17T17:39:23.159912Z",
     "shell.execute_reply": "2022-12-17T17:39:23.159128Z"
    },
    "papermill": {
     "duration": 0.05225,
     "end_time": "2022-12-17T17:39:23.162559",
     "exception": false,
     "start_time": "2022-12-17T17:39:23.110309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list of all the donors\n",
    "donors = np.unique(df_autogluon_train[\"donor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "757bf01a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T17:39:23.264897Z",
     "iopub.status.busy": "2022-12-17T17:39:23.263740Z",
     "iopub.status.idle": "2022-12-17T22:36:12.353594Z",
     "shell.execute_reply": "2022-12-17T22:36:12.352374Z"
    },
    "papermill": {
     "duration": 17809.140959,
     "end_time": "2022-12-17T22:36:12.356617",
     "exception": false,
     "start_time": "2022-12-17T17:39:23.215658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec9e77bf433481996538d1155ed8910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AutoGluon Progress:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_173923/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_173923/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD127\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31724.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t1.9s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0662\t = Validation score   (pearsonr)\n",
      "\t59.55s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0662\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0814\t = Validation score   (pearsonr)\n",
      "\t59.21s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0814\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 143.32s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_173923/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_174149/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_174149/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD127\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31306.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2091\t = Validation score   (pearsonr)\n",
      "\t66.76s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2091\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2046\t = Validation score   (pearsonr)\n",
      "\t68.39s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2046\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.55s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_174149/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_174421/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_174421/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD127\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31025.3 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1519\t = Validation score   (pearsonr)\n",
      "\t69.89s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1519\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1533\t = Validation score   (pearsonr)\n",
      "\t68.23s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1533\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 153.28s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_174421/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_174656/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_174656/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD45\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31348.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6564\t = Validation score   (pearsonr)\n",
      "\t126.28s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6564\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.653\t = Validation score   (pearsonr)\n",
      "\t77.62s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.653\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 218.86s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_174656/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_175037/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_175037/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD45\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31314.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6513\t = Validation score   (pearsonr)\n",
      "\t108.55s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6513\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6482\t = Validation score   (pearsonr)\n",
      "\t94.47s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6482\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 218.37s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_175037/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_175417/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_175417/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD45\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31188.3 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5172\t = Validation score   (pearsonr)\n",
      "\t65.98s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5172\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5149\t = Validation score   (pearsonr)\n",
      "\t70.19s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5149\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 154.91s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_175417/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_175653/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_175653/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD22\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31345.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2667\t = Validation score   (pearsonr)\n",
      "\t60.33s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2667\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1999\t = Validation score   (pearsonr)\n",
      "\t81.0s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1999\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 157.57s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_175653/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_175932/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_175932/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD22\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31321.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.49s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2071\t = Validation score   (pearsonr)\n",
      "\t83.58s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2071\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2393\t = Validation score   (pearsonr)\n",
      "\t88.1s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2393\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 187.34s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_175932/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_180242/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_180242/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD22\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31330.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1989\t = Validation score   (pearsonr)\n",
      "\t58.34s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1989\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.181\t = Validation score   (pearsonr)\n",
      "\t58.29s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.181\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.94s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_180242/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_180456/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_180456/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD71\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31066.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8354\t = Validation score   (pearsonr)\n",
      "\t167.0s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8354\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8412\t = Validation score   (pearsonr)\n",
      "\t90.97s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8412\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 273.51s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_180456/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_180932/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_180932/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD71\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31298.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.54s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6238\t = Validation score   (pearsonr)\n",
      "\t166.46s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6238\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.848\t = Validation score   (pearsonr)\n",
      "\t177.92s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.848\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 360.68s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_180932/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_181537/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_181537/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD71\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31356.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8676\t = Validation score   (pearsonr)\n",
      "\t195.23s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8676\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "E1217 18:19:03.311208346     245 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\t0.8674\t = Validation score   (pearsonr)\n",
      "\t87.38s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8674\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 299.48s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_181537/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_182039/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_182039/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD26\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31337.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5113\t = Validation score   (pearsonr)\n",
      "\t70.68s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5113\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5103\t = Validation score   (pearsonr)\n",
      "\t75.11s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5103\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 160.46s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_182039/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_182321/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_182321/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD26\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31352.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5309\t = Validation score   (pearsonr)\n",
      "\t78.58s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5309\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.522\t = Validation score   (pearsonr)\n",
      "\t70.86s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.522\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 164.71s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_182321/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_182607/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_182607/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD26\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31308.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6304\t = Validation score   (pearsonr)\n",
      "\t76.57s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6304\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6181\t = Validation score   (pearsonr)\n",
      "\t72.82s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6181\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 164.67s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_182607/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_182853/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_182853/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD115\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31337.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6476\t = Validation score   (pearsonr)\n",
      "\t113.71s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6476\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6464\t = Validation score   (pearsonr)\n",
      "\t88.44s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6464\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 216.96s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_182853/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_183231/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_183231/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD115\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30972.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6884\t = Validation score   (pearsonr)\n",
      "\t114.87s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6884\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6817\t = Validation score   (pearsonr)\n",
      "\t71.77s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6817\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 201.98s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_183231/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_183555/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_183555/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD115\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31318.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6515\t = Validation score   (pearsonr)\n",
      "\t62.6s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6515\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6394\t = Validation score   (pearsonr)\n",
      "\t61.99s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6394\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_183555/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_183816/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_183816/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD63\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31040.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5726\t = Validation score   (pearsonr)\n",
      "\t68.58s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5726\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5798\t = Validation score   (pearsonr)\n",
      "\t70.17s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5798\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 154.07s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_183816/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_184052/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_184052/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD63\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31281.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6438\t = Validation score   (pearsonr)\n",
      "\t109.98s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6438\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6402\t = Validation score   (pearsonr)\n",
      "\t81.27s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6402\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 206.76s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_184052/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_184421/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_184421/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD63\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31160.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.53s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.489\t = Validation score   (pearsonr)\n",
      "\t65.78s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.489\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4854\t = Validation score   (pearsonr)\n",
      "\t65.89s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4854\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 147.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_184421/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_184649/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_184649/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD304\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30354.1 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5337\t = Validation score   (pearsonr)\n",
      "\t94.65s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5337\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5217\t = Validation score   (pearsonr)\n",
      "\t91.62s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5217\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 201.07s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_184649/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_185011/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_185011/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD304\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31021.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5435\t = Validation score   (pearsonr)\n",
      "\t59.83s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5435\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5356\t = Validation score   (pearsonr)\n",
      "\t60.53s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5356\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 135.45s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_185011/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_185228/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_185228/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD304\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31003.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3523\t = Validation score   (pearsonr)\n",
      "\t75.24s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3523\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4581\t = Validation score   (pearsonr)\n",
      "\t59.58s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4581\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.21s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_185228/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_185501/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_185501/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD36\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31353.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7914\t = Validation score   (pearsonr)\n",
      "\t153.44s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7914\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7863\t = Validation score   (pearsonr)\n",
      "\t81.21s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7863\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 249.62s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_185501/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_185912/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_185912/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD36\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31295.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8184\t = Validation score   (pearsonr)\n",
      "\t182.03s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8184\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8015\t = Validation score   (pearsonr)\n",
      "\t79.56s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8015\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 276.55s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_185912/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_190351/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_190351/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD36\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31295.8 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8845\t = Validation score   (pearsonr)\n",
      "\t122.47s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8845\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.884\t = Validation score   (pearsonr)\n",
      "\t77.25s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.884\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 214.36s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_190351/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_190727/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_190727/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD172a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31172.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.133\t = Validation score   (pearsonr)\n",
      "\t57.86s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.133\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1489\t = Validation score   (pearsonr)\n",
      "\t58.47s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1489\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.67s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_190727/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_190940/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_190940/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD172a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31236.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0782\t = Validation score   (pearsonr)\n",
      "\t56.39s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0782\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0803\t = Validation score   (pearsonr)\n",
      "\t56.23s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0803\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 127.16s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_190940/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_191149/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_191149/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD172a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31310.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.28s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0599\t = Validation score   (pearsonr)\n",
      "\t58.9s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0599\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0444\t = Validation score   (pearsonr)\n",
      "\t62.86s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0444\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 136.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_191149/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_191407/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_191407/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD72\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31296.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3822\t = Validation score   (pearsonr)\n",
      "\t100.2s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3822\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4317\t = Validation score   (pearsonr)\n",
      "\t95.05s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4317\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 210.38s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_191407/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_191740/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_191740/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD72\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31324.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5103\t = Validation score   (pearsonr)\n",
      "\t106.74s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5103\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4881\t = Validation score   (pearsonr)\n",
      "\t90.61s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4881\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 212.53s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_191740/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_192114/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_192114/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD72\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31318.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2524\t = Validation score   (pearsonr)\n",
      "\t74.69s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2524\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2737\t = Validation score   (pearsonr)\n",
      "\t78.91s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2737\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 169.15s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_192114/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_192405/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_192405/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31314.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4924\t = Validation score   (pearsonr)\n",
      "\t63.83s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4924\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4969\t = Validation score   (pearsonr)\n",
      "\t65.03s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4969\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 144.13s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_192405/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_192632/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_192632/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31295.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4887\t = Validation score   (pearsonr)\n",
      "\t61.56s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4887\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4725\t = Validation score   (pearsonr)\n",
      "\t60.79s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4725\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_192632/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_192851/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_192851/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30982.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5445\t = Validation score   (pearsonr)\n",
      "\t62.66s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5445\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5322\t = Validation score   (pearsonr)\n",
      "\t61.49s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5322\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_192851/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_193112/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_193112/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD93\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30091.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.13\t = Validation score   (pearsonr)\n",
      "\t61.24s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.13\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1178\t = Validation score   (pearsonr)\n",
      "\t61.03s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1178\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.22s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_193112/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_193330/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_193330/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD93\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30322.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2524\t = Validation score   (pearsonr)\n",
      "\t83.88s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2524\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1928\t = Validation score   (pearsonr)\n",
      "\t69.65s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1928\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 169.02s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_193330/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_193621/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_193621/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD93\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31254.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.47s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1533\t = Validation score   (pearsonr)\n",
      "\t73.77s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1533\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1334\t = Validation score   (pearsonr)\n",
      "\t72.99s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1334\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 161.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_193621/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_193904/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_193904/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31262.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1352\t = Validation score   (pearsonr)\n",
      "\t57.75s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1352\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1498\t = Validation score   (pearsonr)\n",
      "\t57.71s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1498\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.31s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_193904/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_194116/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_194116/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31307.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3461\t = Validation score   (pearsonr)\n",
      "\t87.49s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3461\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.344\t = Validation score   (pearsonr)\n",
      "\t72.06s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.344\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 178.11s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_194116/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_194415/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_194415/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30978.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.55s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1241\t = Validation score   (pearsonr)\n",
      "\t86.26s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1241\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1298\t = Validation score   (pearsonr)\n",
      "\t74.93s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1298\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 177.46s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_194415/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_194715/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_194715/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49d\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31272.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.672\t = Validation score   (pearsonr)\n",
      "\t135.61s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.672\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.668\t = Validation score   (pearsonr)\n",
      "\t96.96s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.668\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 247.61s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_194715/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_195125/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_195125/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49d\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31236.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6705\t = Validation score   (pearsonr)\n",
      "\t127.68s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6705\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.667\t = Validation score   (pearsonr)\n",
      "\t84.1s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.667\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 227.26s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_195125/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_195514/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_195514/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49d\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31298.54 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5855\t = Validation score   (pearsonr)\n",
      "\t66.86s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5855\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5975\t = Validation score   (pearsonr)\n",
      "\t68.0s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5975\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.23s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_195514/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_195746/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_195746/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD73\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31251.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0667\t = Validation score   (pearsonr)\n",
      "\t62.78s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0667\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0812\t = Validation score   (pearsonr)\n",
      "\t62.67s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0812\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 140.53s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_195746/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_200009/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_200009/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD73\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31218.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1229\t = Validation score   (pearsonr)\n",
      "\t69.47s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1229\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1235\t = Validation score   (pearsonr)\n",
      "\t87.35s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1235\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 172.48s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_200009/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_200304/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_200304/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD73\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31251.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0656\t = Validation score   (pearsonr)\n",
      "\t61.91s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0656\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0617\t = Validation score   (pearsonr)\n",
      "\t61.87s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0617\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.97s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_200304/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_200524/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_200524/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD9\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31250.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6694\t = Validation score   (pearsonr)\n",
      "\t123.72s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6694\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6656\t = Validation score   (pearsonr)\n",
      "\t81.72s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6656\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 220.56s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_200524/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_200907/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_200907/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD9\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31221.1 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7204\t = Validation score   (pearsonr)\n",
      "\t114.57s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7204\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7176\t = Validation score   (pearsonr)\n",
      "\t98.53s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7176\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 229.28s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_200907/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_201258/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_201258/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD9\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31262.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6516\t = Validation score   (pearsonr)\n",
      "\t110.6s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6516\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6424\t = Validation score   (pearsonr)\n",
      "\t83.43s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6424\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 209.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_201258/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_201629/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_201629/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVa7.2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31226.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0345\t = Validation score   (pearsonr)\n",
      "\t59.87s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0345\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.025\t = Validation score   (pearsonr)\n",
      "\t70.06s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.025\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 145.08s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_201629/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_201855/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_201855/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVa7.2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30898.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0185\t = Validation score   (pearsonr)\n",
      "\t57.3s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0185\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0168\t = Validation score   (pearsonr)\n",
      "\t57.89s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0168\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.19s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_201855/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_202107/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_202107/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVa7.2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30967.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0063\t = Validation score   (pearsonr)\n",
      "\t57.49s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0063\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0013\t = Validation score   (pearsonr)\n",
      "\t58.21s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0013\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.52s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_202107/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_202320/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_202320/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVd2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30904.85 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0306\t = Validation score   (pearsonr)\n",
      "\t68.31s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0306\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0295\t = Validation score   (pearsonr)\n",
      "\t89.29s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0295\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 172.51s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_202320/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_202614/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_202614/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVd2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31169.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0129\t = Validation score   (pearsonr)\n",
      "\t55.73s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0129\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0055\t = Validation score   (pearsonr)\n",
      "\t56.0s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0055\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 127.22s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_202614/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_202823/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_202823/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVd2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30966.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0077\t = Validation score   (pearsonr)\n",
      "\t56.3s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.0077\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0042\t = Validation score   (pearsonr)\n",
      "\t56.33s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0042\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 127.83s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_202823/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_203033/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_203033/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: LOX-1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31252.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1625\t = Validation score   (pearsonr)\n",
      "\t62.75s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1625\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1456\t = Validation score   (pearsonr)\n",
      "\t62.2s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1456\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_203033/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_203254/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_203254/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: LOX-1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30291.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.47s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1941\t = Validation score   (pearsonr)\n",
      "\t62.36s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1941\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1983\t = Validation score   (pearsonr)\n",
      "\t61.2s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1983\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.13s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_203254/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_203516/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_203516/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: LOX-1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31183.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.49s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1469\t = Validation score   (pearsonr)\n",
      "\t63.4s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1469\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1778\t = Validation score   (pearsonr)\n",
      "\t67.97s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1778\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 146.54s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_203516/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_203745/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_203745/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31190.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1225\t = Validation score   (pearsonr)\n",
      "\t61.24s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1225\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.121\t = Validation score   (pearsonr)\n",
      "\t61.57s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.121\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_203745/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_204004/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_204004/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31201.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1612\t = Validation score   (pearsonr)\n",
      "\t59.88s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1612\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1418\t = Validation score   (pearsonr)\n",
      "\t58.05s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1418\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 132.82s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_204004/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_204218/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_204218/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30327.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2019\t = Validation score   (pearsonr)\n",
      "\t69.1s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2019\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1913\t = Validation score   (pearsonr)\n",
      "\t63.24s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1913\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 146.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_204218/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_204447/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_204447/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158e1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30881.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t1.9s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0099\t = Validation score   (pearsonr)\n",
      "\t57.54s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.0099\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0011\t = Validation score   (pearsonr)\n",
      "\t57.46s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.0011\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.33s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_204447/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_204658/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_204658/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158e1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31179.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.49s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0138\t = Validation score   (pearsonr)\n",
      "\t57.29s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0138\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0265\t = Validation score   (pearsonr)\n",
      "\t56.23s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0265\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 128.46s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_204658/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_204909/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_204909/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158e1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31171.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0071\t = Validation score   (pearsonr)\n",
      "\t56.06s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.0071\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-0.0136\t = Validation score   (pearsonr)\n",
      "\t54.01s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-0.0136\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 124.39s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_204909/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_205114/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_205114/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD142\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31143.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t1.8s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4977\t = Validation score   (pearsonr)\n",
      "\t80.08s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4977\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4845\t = Validation score   (pearsonr)\n",
      "\t90.59s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4845\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 184.31s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_205114/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_205420/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_205420/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD142\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31152.25 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3241\t = Validation score   (pearsonr)\n",
      "\t55.4s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3241\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3074\t = Validation score   (pearsonr)\n",
      "\t54.85s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3074\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 124.45s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_205420/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_205626/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_205626/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD142\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31155.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4985\t = Validation score   (pearsonr)\n",
      "\t55.41s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4985\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4922\t = Validation score   (pearsonr)\n",
      "\t55.7s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4922\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 125.27s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_205626/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_205833/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_205833/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD319\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31124.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t1.8s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0494\t = Validation score   (pearsonr)\n",
      "\t56.78s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0494\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.045\t = Validation score   (pearsonr)\n",
      "\t56.47s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.045\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 126.81s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_205833/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_210041/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_210041/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD319\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30813.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0551\t = Validation score   (pearsonr)\n",
      "\t56.69s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0551\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0505\t = Validation score   (pearsonr)\n",
      "\t58.28s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0505\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.29s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_210041/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_210252/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_210252/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD319\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30829.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.054\t = Validation score   (pearsonr)\n",
      "\t58.13s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.054\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0553\t = Validation score   (pearsonr)\n",
      "\t57.36s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0553\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.26s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_210252/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_210504/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_210504/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD352\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31145.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1751\t = Validation score   (pearsonr)\n",
      "\t58.82s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1751\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1581\t = Validation score   (pearsonr)\n",
      "\t60.89s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1581\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 134.16s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_210504/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_210720/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_210720/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD352\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31120.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1916\t = Validation score   (pearsonr)\n",
      "\t105.92s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1916\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2001\t = Validation score   (pearsonr)\n",
      "\t139.46s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2001\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 261.15s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_210720/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_211144/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_211144/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD352\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31151.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0895\t = Validation score   (pearsonr)\n",
      "\t57.52s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0895\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0929\t = Validation score   (pearsonr)\n",
      "\t58.05s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0929\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.39s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_211144/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_211357/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_211357/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD94\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31188.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1415\t = Validation score   (pearsonr)\n",
      "\t59.48s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1415\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1271\t = Validation score   (pearsonr)\n",
      "\t63.82s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1271\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_211357/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_211616/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_211616/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD94\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31108.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.59s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0464\t = Validation score   (pearsonr)\n",
      "\t59.97s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0464\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0613\t = Validation score   (pearsonr)\n",
      "\t60.23s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0613\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 135.88s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_211616/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_211834/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_211834/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD94\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31128.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0301\t = Validation score   (pearsonr)\n",
      "\t60.64s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0301\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.058\t = Validation score   (pearsonr)\n",
      "\t60.58s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.058\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 136.4s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_211834/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_212053/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_212053/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD162\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31132.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5231\t = Validation score   (pearsonr)\n",
      "\t67.53s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5231\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5265\t = Validation score   (pearsonr)\n",
      "\t68.35s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5265\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.96s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_212053/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_212326/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_212326/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD162\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31144.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5422\t = Validation score   (pearsonr)\n",
      "\t66.56s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5422\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5435\t = Validation score   (pearsonr)\n",
      "\t74.24s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5435\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 156.85s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_212326/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_212605/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_212605/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD162\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31168.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5133\t = Validation score   (pearsonr)\n",
      "\t67.21s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5133\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5206\t = Validation score   (pearsonr)\n",
      "\t66.99s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5206\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.27s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_212605/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_212838/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_212838/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD85j\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31124.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.46s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3029\t = Validation score   (pearsonr)\n",
      "\t63.84s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3029\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3215\t = Validation score   (pearsonr)\n",
      "\t63.85s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3215\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 143.08s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_212838/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_213103/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_213103/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD85j\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31161.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3285\t = Validation score   (pearsonr)\n",
      "\t63.45s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3285\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3281\t = Validation score   (pearsonr)\n",
      "\t61.02s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3281\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 140.01s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_213103/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_213325/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_213325/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD85j\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30831.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.51s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2928\t = Validation score   (pearsonr)\n",
      "\t61.58s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2928\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2779\t = Validation score   (pearsonr)\n",
      "\t61.56s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2779\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.69s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_213325/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_213545/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_213545/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD23\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31157.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2631\t = Validation score   (pearsonr)\n",
      "\t107.35s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2631\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2548\t = Validation score   (pearsonr)\n",
      "\t134.99s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2548\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 257.65s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_213545/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_214004/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_214004/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD23\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30793.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1229\t = Validation score   (pearsonr)\n",
      "\t60.66s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1229\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1075\t = Validation score   (pearsonr)\n",
      "\t60.77s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1075\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.16s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_214004/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_214222/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_214222/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD23\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30525.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1561\t = Validation score   (pearsonr)\n",
      "\t61.23s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1561\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1325\t = Validation score   (pearsonr)\n",
      "\t61.41s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1325\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.0s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_214222/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_214442/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_214442/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD328\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31132.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4191\t = Validation score   (pearsonr)\n",
      "\t75.75s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4191\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4457\t = Validation score   (pearsonr)\n",
      "\t122.64s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4457\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 213.38s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_214442/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_214818/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_214818/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD328\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31104.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.55s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5467\t = Validation score   (pearsonr)\n",
      "\t83.89s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5467\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6203\t = Validation score   (pearsonr)\n",
      "\t68.44s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6203\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 167.65s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_214818/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_215108/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_215108/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD328\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31152.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4627\t = Validation score   (pearsonr)\n",
      "\t61.39s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4627\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4685\t = Validation score   (pearsonr)\n",
      "\t80.15s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4685\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 156.66s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_215108/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_215347/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_215347/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: HLA-E\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31083.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1567\t = Validation score   (pearsonr)\n",
      "\t62.5s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1567\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1352\t = Validation score   (pearsonr)\n",
      "\t61.85s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1352\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.07s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_215347/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_215608/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_215608/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: HLA-E\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30187.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1614\t = Validation score   (pearsonr)\n",
      "\t59.8s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1614\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1593\t = Validation score   (pearsonr)\n",
      "\t60.31s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1593\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 135.08s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_215608/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_215824/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_215824/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: HLA-E\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30576.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.5s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1038\t = Validation score   (pearsonr)\n",
      "\t66.52s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1038\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0563\t = Validation score   (pearsonr)\n",
      "\t60.24s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0563\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 141.97s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_215824/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_220048/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_220048/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD82\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31096.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t1.9s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7099\t = Validation score   (pearsonr)\n",
      "\t129.32s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7099\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7091\t = Validation score   (pearsonr)\n",
      "\t80.66s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7091\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 225.13s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_220048/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_220435/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_220435/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD82\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31132.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6575\t = Validation score   (pearsonr)\n",
      "\t68.06s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6575\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.656\t = Validation score   (pearsonr)\n",
      "\t67.95s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.656\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 151.67s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_220435/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_220708/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_220708/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD82\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30842.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6216\t = Validation score   (pearsonr)\n",
      "\t68.92s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6216\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6286\t = Validation score   (pearsonr)\n",
      "\t69.48s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6286\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 154.75s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_220708/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_220945/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_220945/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD101\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31125.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6074\t = Validation score   (pearsonr)\n",
      "\t81.43s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6074\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6071\t = Validation score   (pearsonr)\n",
      "\t79.59s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6071\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 176.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_220945/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_221243/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_221243/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD101\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31113.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.1s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6405\t = Validation score   (pearsonr)\n",
      "\t98.94s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6405\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5761\t = Validation score   (pearsonr)\n",
      "\t74.27s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5761\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 188.26s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_221243/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_221553/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_221553/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD101\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31130.59 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.52s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4788\t = Validation score   (pearsonr)\n",
      "\t93.21s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4788\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4816\t = Validation score   (pearsonr)\n",
      "\t83.55s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4816\t = Validation score   (pearsonr)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 192.25s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_221553/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_221908/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_221908/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD88\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31094.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7325\t = Validation score   (pearsonr)\n",
      "\t65.77s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7325\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7237\t = Validation score   (pearsonr)\n",
      "\t66.07s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7237\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 146.65s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_221908/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_222135/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_222135/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD88\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29887.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7656\t = Validation score   (pearsonr)\n",
      "\t62.09s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7656\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7652\t = Validation score   (pearsonr)\n",
      "\t61.92s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7652\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_222135/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_222356/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_222356/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD88\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29892.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.48s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7918\t = Validation score   (pearsonr)\n",
      "\t62.77s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7918\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7926\t = Validation score   (pearsonr)\n",
      "\t62.41s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7926\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 140.18s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_222356/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_222619/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_222619/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    17919\n",
      "Train Data Columns: 614\n",
      "Label Column: CD224\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31087.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 45.02 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000115556_PLCD4', 'ENSG00000125726_CD70', 'ENSG00000186407_CD300E', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 43.6 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.33s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2501\t = Validation score   (pearsonr)\n",
      "\t64.35s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2501\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2541\t = Validation score   (pearsonr)\n",
      "\t63.86s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2541\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 142.98s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_222619/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_222844/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_222844/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19648\n",
      "Train Data Columns: 614\n",
      "Label Column: CD224\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31092.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 49.36 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 5): ['ENSG00000102245_CD40LG', 'ENSG00000205502_C2CD4B', 'ENSG00000206531_CD200R1L', 'ENSG00000255443_CD44-AS1', 'ENSG00000255909_PDCD5P1']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 608 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.2s = Fit runtime\n",
      "\t609 features in original data used to generate 609 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 47.8 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2647\t = Validation score   (pearsonr)\n",
      "\t61.18s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2647\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2551\t = Validation score   (pearsonr)\n",
      "\t67.07s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2551\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 148.72s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_222844/\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221217_223114/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221217_223114/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    19223\n",
      "Train Data Columns: 614\n",
      "Label Column: CD224\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31069.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 48.3 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['ENSG00000102245_CD40LG', 'ENSG00000186407_CD300E', 'ENSG00000205502_C2CD4B']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 610 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t2.3s = Fit runtime\n",
      "\t611 features in original data used to generate 611 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 46.92 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.51s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2838\t = Validation score   (pearsonr)\n",
      "\t114.83s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2838\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3324\t = Validation score   (pearsonr)\n",
      "\t163.65s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3324\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 294.75s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221217_223114/\")\n"
     ]
    }
   ],
   "source": [
    "predicator_list = []\n",
    "\n",
    "#Creating model with LightGBM and XGBoost\n",
    "hyperparameters = {\n",
    "    'GBM': [\n",
    "        {}\n",
    "    ]\n",
    "}\n",
    "\n",
    "train_va = []\n",
    "test_va = []\n",
    "\n",
    "train_preds = []\n",
    "test_preds = []\n",
    "\n",
    "starting_gene = 105\n",
    "genes_to_predict = 140\n",
    "\n",
    "for i in tqdm_notebook(range(starting_gene, genes_to_predict), desc=\"AutoGluon Progress\"):\n",
    "    for donor in donors:\n",
    "        df_train = df_autogluon_train.loc[df_autogluon_train.index[np.where(df_autogluon_train[[\"donor\"]]==donor)[0]]]\n",
    "        df_test = df_autogluon_test.loc[df_autogluon_test.index[np.where(df_autogluon_test[[\"donor\"]]==donor)[0]]]\n",
    "        predicator = TabularPredictor(label=df_target.columns[i], problem_type=\"regression\", eval_metric=\"pearsonr\")\n",
    "        df_train = df_train[df_features.columns.tolist()+[\"cell_type\"]+[df_target.columns[i]]]\n",
    "        df_test = df_test[df_features.columns.tolist()+[\"cell_type\"]+[df_target.columns[i]]]\n",
    "        predicator.fit(df_train, presets='best_quality', hyperparameters=hyperparameters, num_bag_folds=4)\n",
    "        train_va = np.concatenate((train_va, df_train[df_target.columns[i]].to_numpy()), axis=None)\n",
    "        test_va = np.concatenate((test_va, df_test[df_target.columns[i]].to_numpy()), axis=None)\n",
    "        train_preds = np.concatenate((train_preds, predicator.predict(df_train)), axis=None)\n",
    "        test_preds = np.concatenate((test_preds, predicator.predict(df_test)), axis=None)\n",
    "        predicator_list.append(predicator)\n",
    "        \n",
    "train_va = np.reshape(train_va, (genes_to_predict-starting_gene, -1))\n",
    "test_va = np.reshape(test_va, (genes_to_predict-starting_gene, -1))\n",
    "\n",
    "train_preds = np.reshape(train_preds, (genes_to_predict-starting_gene, -1))\n",
    "test_preds = np.reshape(test_preds, (genes_to_predict-starting_gene, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27baa575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T22:36:13.432750Z",
     "iopub.status.busy": "2022-12-17T22:36:13.432285Z",
     "iopub.status.idle": "2022-12-17T22:36:13.480417Z",
     "shell.execute_reply": "2022-12-17T22:36:13.479155Z"
    },
    "papermill": {
     "duration": 0.638861,
     "end_time": "2022-12-17T22:36:13.483389",
     "exception": false,
     "start_time": "2022-12-17T22:36:12.844528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"train_va.npy\", train_va)\n",
    "np.save(\"test_va.npy\", test_va)\n",
    "\n",
    "np.save(\"train_preds.npy\", train_preds)\n",
    "np.save(\"test_preds.npy\", test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0587ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T22:36:14.531242Z",
     "iopub.status.busy": "2022-12-17T22:36:14.530787Z",
     "iopub.status.idle": "2022-12-17T22:36:14.594806Z",
     "shell.execute_reply": "2022-12-17T22:36:14.593569Z"
    },
    "papermill": {
     "duration": 0.599464,
     "end_time": "2022-12-17T22:36:14.597903",
     "exception": false,
     "start_time": "2022-12-17T22:36:13.998439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mse_train = mean_squared_error(train_va, train_preds)\n",
    "corrscore_train = correlation_score(train_va, train_preds)\n",
    "\n",
    "mse_test = mean_squared_error(test_va, test_preds)\n",
    "corrscore_test = correlation_score(test_va, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c5935",
   "metadata": {
    "papermill": {
     "duration": 0.495516,
     "end_time": "2022-12-17T22:36:15.605985",
     "exception": false,
     "start_time": "2022-12-17T22:36:15.110469",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.3. Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74a904f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T22:36:16.675380Z",
     "iopub.status.busy": "2022-12-17T22:36:16.674943Z",
     "iopub.status.idle": "2022-12-17T22:36:16.681378Z",
     "shell.execute_reply": "2022-12-17T22:36:16.680156Z"
    },
    "papermill": {
     "duration": 0.58446,
     "end_time": "2022-12-17T22:36:16.683705",
     "exception": false,
     "start_time": "2022-12-17T22:36:16.099245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE train is: 2.520250059004459\n",
      "The correlation score train is: 0.4850869862418375\n",
      "The MSE test is: 3.351813003865147\n",
      "The correlation score test is: 0.39516252988488515\n"
     ]
    }
   ],
   "source": [
    "print(\"The MSE train is:\", mse_train)\n",
    "print(\"The correlation score train is:\", corrscore_train)\n",
    "print(\"The MSE test is:\", mse_test)\n",
    "print(\"The correlation score test is:\", corrscore_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18300.953019,
   "end_time": "2022-12-17T22:36:22.323212",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-17T17:31:21.370193",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a1507839da94102b59a95423a639841": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d0a5bb2ef9fb414fb68d21a51b1ae0f4",
       "placeholder": "​",
       "style": "IPY_MODEL_4a6ee17274244d1e887a1ddc0a6d3a32",
       "value": "AutoGluon Progress: 100%"
      }
     },
     "1c7a11fec4374a7d923a0f5e8dab22b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a6ee17274244d1e887a1ddc0a6d3a32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4ec9e77bf433481996538d1155ed8910": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a1507839da94102b59a95423a639841",
        "IPY_MODEL_6335bd7303be41e3a5527b9f757fd8b6",
        "IPY_MODEL_f997c9cf44c047c7bcf07fde8f79d550"
       ],
       "layout": "IPY_MODEL_d92f8417ff964a39bc173eba8028772d"
      }
     },
     "5447aa49aa774901928d5694fd2f2f6b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6335bd7303be41e3a5527b9f757fd8b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5447aa49aa774901928d5694fd2f2f6b",
       "max": 35.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_897c83bc8a1e48699209ba0ce1065cd9",
       "value": 35.0
      }
     },
     "897c83bc8a1e48699209ba0ce1065cd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d0a5bb2ef9fb414fb68d21a51b1ae0f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d92f8417ff964a39bc173eba8028772d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e99b730972e24e93a127537730940477": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f997c9cf44c047c7bcf07fde8f79d550": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1c7a11fec4374a7d923a0f5e8dab22b9",
       "placeholder": "​",
       "style": "IPY_MODEL_e99b730972e24e93a127537730940477",
       "value": " 35/35 [4:56:49&lt;00:00, 519.73s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
