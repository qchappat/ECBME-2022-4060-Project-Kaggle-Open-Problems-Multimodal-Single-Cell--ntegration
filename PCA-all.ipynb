{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71b14a1a",
   "metadata": {
    "papermill": {
     "duration": 0.007957,
     "end_time": "2022-12-16T14:14:44.026027",
     "exception": false,
     "start_time": "2022-12-16T14:14:44.018070",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Installation of packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95615e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:14:44.043026Z",
     "iopub.status.busy": "2022-12-16T14:14:44.042004Z",
     "iopub.status.idle": "2022-12-16T14:17:19.397411Z",
     "shell.execute_reply": "2022-12-16T14:17:19.395984Z"
    },
    "papermill": {
     "duration": 155.367374,
     "end_time": "2022-12-16T14:17:19.400417",
     "exception": false,
     "start_time": "2022-12-16T14:14:44.033043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (22.1.2)\r\n",
      "Collecting pip\r\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 22.1.2\r\n",
      "    Uninstalling pip-22.1.2:\r\n",
      "      Successfully uninstalled pip-22.1.2\r\n",
      "Successfully installed pip-22.3.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (59.8.0)\r\n",
      "Collecting setuptools\r\n",
      "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (0.37.1)\r\n",
      "Collecting wheel\r\n",
      "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\r\n",
      "Installing collected packages: wheel, setuptools\r\n",
      "  Attempting uninstall: wheel\r\n",
      "    Found existing installation: wheel 0.37.1\r\n",
      "    Uninstalling wheel-0.37.1:\r\n",
      "      Successfully uninstalled wheel-0.37.1\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 59.8.0\r\n",
      "    Uninstalling setuptools-59.8.0:\r\n",
      "      Successfully uninstalled setuptools-59.8.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "thinc 8.0.17 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.10.1 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "spacy 3.3.1 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "google-api-core 1.33.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "gcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2022.8.2 which is incompatible.\r\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 1.12.11 which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed setuptools-65.6.3 wheel-0.38.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mLooking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\r\n",
      "Collecting torch==1.12+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.12.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (189.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.13.0+cpu\r\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.13.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (13.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchtext==0.13.0\r\n",
      "  Downloading torchtext-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.12+cpu) (4.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (1.21.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (9.1.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (2.28.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.13.0) (4.64.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (2022.9.24)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (1.26.12)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (2.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (3.3)\r\n",
      "Installing collected packages: torch, torchvision, torchtext\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0+cpu\r\n",
      "    Uninstalling torch-1.11.0+cpu:\r\n",
      "      Successfully uninstalled torch-1.11.0+cpu\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.12.0+cpu\r\n",
      "    Uninstalling torchvision-0.12.0+cpu:\r\n",
      "      Successfully uninstalled torchvision-0.12.0+cpu\r\n",
      "  Attempting uninstall: torchtext\r\n",
      "    Found existing installation: torchtext 0.12.0\r\n",
      "    Uninstalling torchtext-0.12.0:\r\n",
      "      Successfully uninstalled torchtext-0.12.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchaudio 0.11.0+cpu requires torch==1.11.0, but you have torch 1.12.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "allennlp 2.10.0 requires torch<1.12.0,>=1.10.0, but you have torch 1.12.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires torchvision<0.13.0,>=0.8.1, but you have torchvision 0.13.0+cpu which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0+cpu torchtext-0.13.0 torchvision-0.13.0+cpu\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting autogluon\r\n",
      "  Downloading autogluon-0.6.1-py3-none-any.whl (9.8 kB)\r\n",
      "Collecting autogluon.features==0.6.1\r\n",
      "  Downloading autogluon.features-0.6.1-py3-none-any.whl (59 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m707.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.tabular[all]==0.6.1\r\n",
      "  Downloading autogluon.tabular-0.6.1-py3-none-any.whl (286 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.0/286.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.timeseries[all]==0.6.1\r\n",
      "  Downloading autogluon.timeseries-0.6.1-py3-none-any.whl (103 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.text==0.6.1\r\n",
      "  Downloading autogluon.text-0.6.1-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.vision==0.6.1\r\n",
      "  Downloading autogluon.vision-0.6.1-py3-none-any.whl (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.core[all]==0.6.1\r\n",
      "  Downloading autogluon.core-0.6.1-py3-none-any.whl (226 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.6/226.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting autogluon.multimodal==0.6.1\r\n",
      "  Downloading autogluon.multimodal-0.6.1-py3-none-any.whl (289 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.7/289.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (3.5.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (2.28.1)\r\n",
      "Collecting dask<=2021.11.2,>=2021.09.1\r\n",
      "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (4.64.0)\r\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>=1.2.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.3.5)\r\n",
      "Requirement already satisfied: scipy<1.10.0,>=1.5.4 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.7.3)\r\n",
      "Collecting distributed<=2021.11.2,>=2021.09.1\r\n",
      "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn<1.2,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.0.2)\r\n",
      "Collecting autogluon.common==0.6.1\r\n",
      "  Downloading autogluon.common-0.6.1-py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.21 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.21.6)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.24.93)\r\n",
      "Requirement already satisfied: ray<2.1,>=2.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (2.0.0)\r\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /opt/conda/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (0.2.7)\r\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.features==0.6.1->autogluon) (5.9.1)\r\n",
      "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.19.3)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (3.7)\r\n",
      "Requirement already satisfied: jsonschema<=4.8.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (4.6.1)\r\n",
      "Requirement already satisfied: torch<1.13,>=1.9 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (1.12.0+cpu)\r\n",
      "Requirement already satisfied: text-unidecode<=1.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (1.3)\r\n",
      "Requirement already satisfied: defusedxml<=0.7.1,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.7.1)\r\n",
      "Collecting nlpaug<=1.1.10,>=1.1.10\r\n",
      "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.8/410.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pytorch-metric-learning<1.4.0,>=1.3.0\r\n",
      "  Downloading pytorch_metric_learning-1.3.2-py3-none-any.whl (109 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting seqeval<=1.2.2\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting omegaconf<2.2.0,>=2.1.1\r\n",
      "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: smart-open<5.3.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (5.2.1)\r\n",
      "Collecting transformers<4.24.0,>=4.23.0\r\n",
      "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting nptyping<1.5.0,>=1.4.4\r\n",
      "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\r\n",
      "Requirement already satisfied: fairscale<=0.4.6,>=0.4.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.4.6)\r\n",
      "Collecting timm<0.7.0\r\n",
      "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting Pillow<=9.4.0,>=9.3.0\r\n",
      "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision<0.14.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.13.0+cpu)\r\n",
      "Collecting torchmetrics<0.9.0,>=0.8.0\r\n",
      "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting evaluate<=0.3.0\r\n",
      "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: accelerate<0.14,>=0.9 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.12.0)\r\n",
      "Requirement already satisfied: torchtext<0.14.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.13.0)\r\n",
      "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.95 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.1.97)\r\n",
      "Collecting openmim<=0.2.1,>0.1.5\r\n",
      "  Downloading openmim-0.2.1-py2.py3-none-any.whl (49 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting albumentations<=1.2.0,>=1.1.0\r\n",
      "  Downloading albumentations-1.2.0-py3-none-any.whl (113 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pytorch-lightning<1.8.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (1.7.7)\r\n",
      "Requirement already satisfied: networkx<3.0,>=2.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (2.5)\r\n",
      "Requirement already satisfied: fastai<2.8,>=2.3.1 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (2.7.9)\r\n",
      "Requirement already satisfied: catboost<1.2,>=1.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (1.1)\r\n",
      "Requirement already satisfied: xgboost<1.8,>=1.6 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (1.6.2)\r\n",
      "Requirement already satisfied: lightgbm<3.4,>=3.3 in /opt/conda/lib/python3.7/site-packages (from autogluon.tabular[all]==0.6.1->autogluon) (3.3.2)\r\n",
      "Requirement already satisfied: statsmodels~=0.13.0 in /opt/conda/lib/python3.7/site-packages (from autogluon.timeseries[all]==0.6.1->autogluon) (0.13.2)\r\n",
      "Collecting psutil<6,>=5.7.3\r\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting joblib~=1.1\r\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting gluonts~=0.11.0\r\n",
      "  Downloading gluonts-0.11.5-py3-none-any.whl (1.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sktime<0.14,>=0.13.1\r\n",
      "  Downloading sktime-0.13.4-py3-none-any.whl (7.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pmdarima~=1.8.2\r\n",
      "  Downloading pmdarima-1.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tbats~=1.1\r\n",
      "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: gluoncv<0.10.6,>=0.10.5 in /opt/conda/lib/python3.7/site-packages (from autogluon.vision==0.6.1->autogluon) (0.10.5.post0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from autogluon.common==0.6.1->autogluon.core[all]==0.6.1->autogluon) (65.6.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->autogluon) (6.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->autogluon) (21.3)\r\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.7/site-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.1->autogluon) (0.0.4)\r\n",
      "Collecting albumentations<=1.2.0,>=1.1.0\r\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from albumentations<=1.2.0,>=1.1.0->autogluon.multimodal==0.6.1->autogluon) (4.5.4.60)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (5.10.0)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (0.8.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (1.15.0)\r\n",
      "Requirement already satisfied: partd>=0.3.10 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (0.11.2)\r\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2022.8.2)\r\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.1.0)\r\n",
      "Requirement already satisfied: click>=6.6 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (8.0.4)\r\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.4.0)\r\n",
      "Requirement already satisfied: tornado>=5 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (6.1)\r\n",
      "Requirement already satisfied: tblib>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.7.0)\r\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.0.4)\r\n",
      "Requirement already satisfied: zict>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.2.0)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (3.1.2)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.3.5.1)\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (2.1.0)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (3.0.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.10.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (4.13.0)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.70.13)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.18.0)\r\n",
      "Requirement already satisfied: fastcore<1.6,>=1.4.5 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.5.27)\r\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (22.3.1)\r\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.0.3)\r\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.0.7)\r\n",
      "Requirement already satisfied: spacy<4 in /opt/conda/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.3.1)\r\n",
      "Requirement already satisfied: autocfg in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (0.0.8)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (4.5.4.60)\r\n",
      "Requirement already satisfied: yacs in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (0.1.8)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (2.6.0)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.7/site-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.1->autogluon) (4.4.0)\r\n",
      "Requirement already satisfied: pydantic~=1.7 in /opt/conda/lib/python3.7/site-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.1->autogluon) (1.8.2)\r\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.7/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.1->autogluon) (0.10.9.7)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.1->autogluon) (0.18.2)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (0.18.1)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (21.4.0)\r\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (5.8.0)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.6.1->autogluon) (0.38.4)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx<3.0,>=2.3->autogluon.tabular[all]==0.6.1->autogluon) (5.1.1)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.6.1->autogluon) (2021.11.10)\r\n",
      "Collecting typish>=1.7.0\r\n",
      "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\r\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hCollecting model-index\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (0.4.5)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (0.9.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.7/site-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (12.1.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->autogluon) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->autogluon) (2022.1)\r\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /opt/conda/lib/python3.7/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.1->autogluon) (0.29.32)\r\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.1->autogluon) (1.26.12)\r\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.3.2)\r\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (2.10.1)\r\n",
      "Requirement already satisfied: virtualenv in /opt/conda/lib/python3.7/site-packages (from ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (20.15.1)\r\n",
      "Requirement already satisfied: grpcio<=1.43.0,>=1.28.1 in /opt/conda/lib/python3.7/site-packages (from ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.43.0)\r\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.7/site-packages (from ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /opt/conda/lib/python3.7/site-packages (from ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (3.19.4)\r\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.7/site-packages (from ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.2.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (3.7.1)\r\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.7/site-packages (from ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (2.5.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (2.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (3.3)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->autogluon) (1.3.0)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->autogluon) (2021.11.2)\r\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->autogluon) (2.19.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<1.2,>=1.0.0->autogluon.core[all]==0.6.1->autogluon) (3.1.0)\r\n",
      "Collecting deprecated>=1.2.13\r\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Requirement already satisfied: numba>=0.53 in /opt/conda/lib/python3.7/site-packages (from sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (0.55.2)\r\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.7/site-packages (from statsmodels~=0.13.0->autogluon.timeseries[all]==0.6.1->autogluon) (0.5.2)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<4.24.0,>=4.23.0->autogluon.multimodal==0.6.1->autogluon) (0.12.1)\r\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (0.6.0)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (1.0.1)\r\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.93 in /opt/conda/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (1.27.93)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (4.33.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (0.11.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (1.4.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (3.0.9)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (3.8.1)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (8.0.0)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.13->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (1.12.1)\r\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (3.8.0)\r\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba>=0.53->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (0.38.1)\r\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.7/site-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.0.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.0.9)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.0.8)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (2.0.7)\r\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.4.2)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.10.1)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (1.0.3)\r\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (8.0.17)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.0.10)\r\n",
      "Collecting typing-extensions~=4.0\r\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.6.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (3.3.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (2.4.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (0.7.9)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (2.0.8)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.15.0)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (2.2.2)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (1.35.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (3.3.7)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.4.6)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (1.8.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.6.1)\r\n",
      "Requirement already satisfied: heapdict in /opt/conda/lib/python3.7/site-packages (from zict>=0.1.3->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.1.1)\r\n",
      "Collecting ordered-set\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (8.0.1)\r\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from rich->openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (0.9.1)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich->openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (2.12.0)\r\n",
      "Requirement already satisfied: platformdirs<3,>=2 in /opt/conda/lib/python3.7/site-packages (from virtualenv->ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (2.5.1)\r\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from virtualenv->ray<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (0.3.4)\r\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.13.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (6.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (1.7.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (4.0.2)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (4.8)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (1.3.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (3.2.0)\r\n",
      "Building wheels for collected packages: antlr4-python3-runtime, seqeval\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=a121f40ba134f60c662bb80b5043f306a60000ae3792605d8d5b1e80522d4ab5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/ef/75/1b8c6588a8a8a15d5a9136608a9d65172a226577e7ae89da31\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16164 sha256=568c8eaf5706e9706296856f368899935cc0a186da1647ad2171268332267c86\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b2/a1/b7/0d3b008d0c77cd57332d724b92cf7650b4185b493dc785f00a\r\n",
      "Successfully built antlr4-python3-runtime seqeval\r\n",
      "Installing collected packages: typish, antlr4-python3-runtime, typing-extensions, psutil, Pillow, ordered-set, omegaconf, nptyping, joblib, deprecated, dask, torchmetrics, seqeval, nlpaug, gluonts, transformers, timm, sktime, pytorch-metric-learning, pmdarima, model-index, distributed, albumentations, tbats, openmim, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.vision, autogluon.timeseries, autogluon.text, autogluon\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.4.0\r\n",
      "    Uninstalling typing_extensions-4.4.0:\r\n",
      "      Successfully uninstalled typing_extensions-4.4.0\r\n",
      "  Attempting uninstall: psutil\r\n",
      "    Found existing installation: psutil 5.9.1\r\n",
      "    Uninstalling psutil-5.9.1:\r\n",
      "      Successfully uninstalled psutil-5.9.1\r\n",
      "  Attempting uninstall: Pillow\r\n",
      "    Found existing installation: Pillow 9.1.1\r\n",
      "    Uninstalling Pillow-9.1.1:\r\n",
      "      Successfully uninstalled Pillow-9.1.1\r\n",
      "  Attempting uninstall: joblib\r\n",
      "    Found existing installation: joblib 1.0.1\r\n",
      "    Uninstalling joblib-1.0.1:\r\n",
      "      Successfully uninstalled joblib-1.0.1\r\n",
      "  Attempting uninstall: dask\r\n",
      "    Found existing installation: dask 2022.2.0\r\n",
      "    Uninstalling dask-2022.2.0:\r\n",
      "      Successfully uninstalled dask-2022.2.0\r\n",
      "  Attempting uninstall: torchmetrics\r\n",
      "    Found existing installation: torchmetrics 0.10.0\r\n",
      "    Uninstalling torchmetrics-0.10.0:\r\n",
      "      Successfully uninstalled torchmetrics-0.10.0\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.20.1\r\n",
      "    Uninstalling transformers-4.20.1:\r\n",
      "      Successfully uninstalled transformers-4.20.1\r\n",
      "  Attempting uninstall: distributed\r\n",
      "    Found existing installation: distributed 2022.2.0\r\n",
      "    Uninstalling distributed-2022.2.0:\r\n",
      "      Successfully uninstalled distributed-2022.2.0\r\n",
      "  Attempting uninstall: albumentations\r\n",
      "    Found existing installation: albumentations 1.3.0\r\n",
      "    Uninstalling albumentations-1.3.0:\r\n",
      "      Successfully uninstalled albumentations-1.3.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\r\n",
      "beatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\r\n",
      "tensorflow 2.6.4 requires h5py~=3.1.0, but you have h5py 3.7.0 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires tensorboard<2.7,>=2.6.0, but you have tensorboard 2.10.1 which is incompatible.\r\n",
      "tensorflow 2.6.4 requires typing-extensions<3.11,>=3.7, but you have typing-extensions 4.1.1 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "tensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "tensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\r\n",
      "pdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\r\n",
      "pandas-profiling 3.1.0 requires joblib~=1.0.1, but you have joblib 1.2.0 which is incompatible.\r\n",
      "pandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\r\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.5.1 which is incompatible.\r\n",
      "apache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\r\n",
      "allennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\r\n",
      "allennlp 2.10.0 requires torch<1.12.0,>=1.10.0, but you have torch 1.12.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires torchvision<0.13.0,>=0.8.1, but you have torchvision 0.13.0+cpu which is incompatible.\r\n",
      "allennlp 2.10.0 requires transformers<4.21,>=4.1, but you have transformers 4.23.1 which is incompatible.\r\n",
      "aiobotocore 2.4.0 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.27.93 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed Pillow-9.3.0 albumentations-1.1.0 antlr4-python3-runtime-4.8 autogluon-0.6.1 autogluon.common-0.6.1 autogluon.core-0.6.1 autogluon.features-0.6.1 autogluon.multimodal-0.6.1 autogluon.tabular-0.6.1 autogluon.text-0.6.1 autogluon.timeseries-0.6.1 autogluon.vision-0.6.1 dask-2021.11.2 deprecated-1.2.13 distributed-2021.11.2 evaluate-0.3.0 gluonts-0.11.5 joblib-1.2.0 model-index-0.1.11 nlpaug-1.1.10 nptyping-1.4.4 omegaconf-2.1.2 openmim-0.2.1 ordered-set-4.1.0 pmdarima-1.8.5 psutil-5.8.0 pytorch-metric-learning-1.3.2 seqeval-1.2.2 sktime-0.13.4 tbats-1.1.2 timm-0.6.12 torchmetrics-0.8.2 transformers-4.23.1 typing-extensions-4.1.1 typish-1.9.3\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Installation of AutoGluon\n",
    "!pip3 install -U pip\n",
    "!pip3 install -U setuptools wheel\n",
    "!pip3 install torch==1.12+cpu torchvision==0.13.0+cpu torchtext==0.13.0 -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "!pip3 install autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a108b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:17:19.464528Z",
     "iopub.status.busy": "2022-12-16T14:17:19.464069Z",
     "iopub.status.idle": "2022-12-16T14:17:19.474761Z",
     "shell.execute_reply": "2022-12-16T14:17:19.473588Z"
    },
    "papermill": {
     "duration": 0.046428,
     "end_time": "2022-12-16T14:17:19.477696",
     "exception": false,
     "start_time": "2022-12-16T14:17:19.431268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restating the kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e31381",
   "metadata": {
    "papermill": {
     "duration": 0.030875,
     "end_time": "2022-12-16T14:17:19.540058",
     "exception": false,
     "start_time": "2022-12-16T14:17:19.509183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Importation of packages and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9270b076",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:17:19.604834Z",
     "iopub.status.busy": "2022-12-16T14:17:19.604392Z",
     "iopub.status.idle": "2022-12-16T14:17:21.440289Z",
     "shell.execute_reply": "2022-12-16T14:17:21.438959Z"
    },
    "papermill": {
     "duration": 1.870923,
     "end_time": "2022-12-16T14:17:21.443027",
     "exception": false,
     "start_time": "2022-12-16T14:17:19.572104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/open-problems-multimodal/sample_submission.csv\n",
      "/kaggle/input/open-problems-multimodal/train_cite_targets.h5\n",
      "/kaggle/input/open-problems-multimodal/metadata_cite_day_2_donor_27678.csv\n",
      "/kaggle/input/open-problems-multimodal/test_multi_inputs.h5\n",
      "/kaggle/input/open-problems-multimodal/evaluation_ids.csv\n",
      "/kaggle/input/open-problems-multimodal/train_cite_inputs.h5\n",
      "/kaggle/input/open-problems-multimodal/train_multi_targets.h5\n",
      "/kaggle/input/open-problems-multimodal/train_multi_inputs.h5\n",
      "/kaggle/input/open-problems-multimodal/metadata.csv\n",
      "/kaggle/input/open-problems-multimodal/test_cite_inputs_day_2_donor_27678.h5\n",
      "/kaggle/input/open-problems-multimodal/test_cite_inputs.h5\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import autogluon\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#Import files from Kaggle\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ecd67",
   "metadata": {
    "papermill": {
     "duration": 0.03003,
     "end_time": "2022-12-16T14:17:21.505070",
     "exception": false,
     "start_time": "2022-12-16T14:17:21.475040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Opening files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e374f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:17:21.568319Z",
     "iopub.status.busy": "2022-12-16T14:17:21.567843Z",
     "iopub.status.idle": "2022-12-16T14:18:13.736570Z",
     "shell.execute_reply": "2022-12-16T14:18:13.735476Z"
    },
    "papermill": {
     "duration": 52.203912,
     "end_time": "2022-12-16T14:18:13.739569",
     "exception": false,
     "start_time": "2022-12-16T14:17:21.535657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features = pd.read_hdf(\"/kaggle/input/open-problems-multimodal/train_cite_inputs.h5\")#features_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c33009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:18:13.803471Z",
     "iopub.status.busy": "2022-12-16T14:18:13.802533Z",
     "iopub.status.idle": "2022-12-16T14:18:14.470405Z",
     "shell.execute_reply": "2022-12-16T14:18:14.468975Z"
    },
    "papermill": {
     "duration": 0.702722,
     "end_time": "2022-12-16T14:18:14.473297",
     "exception": false,
     "start_time": "2022-12-16T14:18:13.770575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_target = pd.read_hdf(\"/kaggle/input/open-problems-multimodal/train_cite_targets.h5\")#target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ccfa4e",
   "metadata": {
    "papermill": {
     "duration": 0.030052,
     "end_time": "2022-12-16T14:18:14.533848",
     "exception": false,
     "start_time": "2022-12-16T14:18:14.503796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb15e5b",
   "metadata": {
    "papermill": {
     "duration": 0.030147,
     "end_time": "2022-12-16T14:18:14.594445",
     "exception": false,
     "start_time": "2022-12-16T14:18:14.564298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.1. Removing the columns with only 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0dc7ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:18:14.657307Z",
     "iopub.status.busy": "2022-12-16T14:18:14.656872Z",
     "iopub.status.idle": "2022-12-16T14:18:29.604670Z",
     "shell.execute_reply": "2022-12-16T14:18:29.599173Z"
    },
    "papermill": {
     "duration": 14.98281,
     "end_time": "2022-12-16T14:18:29.607638",
     "exception": false,
     "start_time": "2022-12-16T14:18:14.624828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features.loc['Total']= df_features.sum()\n",
    "unwanted = [column for column in df_features.columns \n",
    "            if df_features[column][\"Total\"]==0]\n",
    "df_features.drop(unwanted, axis=1, inplace=True)\n",
    "df_features.drop(\"Total\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44778b95",
   "metadata": {
    "papermill": {
     "duration": 0.030797,
     "end_time": "2022-12-16T14:18:29.690293",
     "exception": false,
     "start_time": "2022-12-16T14:18:29.659496",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.2. Finding the genes directly linked to the target protein levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f292c",
   "metadata": {
    "papermill": {
     "duration": 0.030828,
     "end_time": "2022-12-16T14:18:29.752518",
     "exception": false,
     "start_time": "2022-12-16T14:18:29.721690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We use naming conventions to find the genes directly linked to our targeted protein levels by finding in each gene if the name of the protein is contained in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3deb05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:18:29.816922Z",
     "iopub.status.busy": "2022-12-16T14:18:29.816417Z",
     "iopub.status.idle": "2022-12-16T14:18:30.416976Z",
     "shell.execute_reply": "2022-12-16T14:18:30.415602Z"
    },
    "papermill": {
     "duration": 0.636917,
     "end_time": "2022-12-16T14:18:30.420380",
     "exception": false,
     "start_time": "2022-12-16T14:18:29.783463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for protein in df_target.columns:\n",
    "    for gene in df_features.columns:\n",
    "        if protein in gene:\n",
    "            features_list.append(gene)\n",
    "features_list = np.unique(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31097a10",
   "metadata": {
    "papermill": {
     "duration": 0.030368,
     "end_time": "2022-12-16T14:18:30.482548",
     "exception": false,
     "start_time": "2022-12-16T14:18:30.452180",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.3. Performing PCA on the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cddb95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:18:30.546003Z",
     "iopub.status.busy": "2022-12-16T14:18:30.545589Z",
     "iopub.status.idle": "2022-12-16T14:18:32.556867Z",
     "shell.execute_reply": "2022-12-16T14:18:32.555806Z"
    },
    "papermill": {
     "duration": 2.046291,
     "end_time": "2022-12-16T14:18:32.559522",
     "exception": false,
     "start_time": "2022-12-16T14:18:30.513231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Spliting the training set into two: the genes directly linked to our proteins and the others\n",
    "df_to_pca = df_features.drop(features_list, axis=1)\n",
    "df_features = df_features[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27980f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:18:32.625209Z",
     "iopub.status.busy": "2022-12-16T14:18:32.624810Z",
     "iopub.status.idle": "2022-12-16T14:18:32.629141Z",
     "shell.execute_reply": "2022-12-16T14:18:32.628358Z"
    },
    "papermill": {
     "duration": 0.039248,
     "end_time": "2022-12-16T14:18:32.631140",
     "exception": false,
     "start_time": "2022-12-16T14:18:32.591892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separating out the features\n",
    "x = df_to_pca.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d85a4a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:18:32.695339Z",
     "iopub.status.busy": "2022-12-16T14:18:32.694172Z",
     "iopub.status.idle": "2022-12-16T14:22:21.311820Z",
     "shell.execute_reply": "2022-12-16T14:22:21.308848Z"
    },
    "papermill": {
     "duration": 228.6556,
     "end_time": "2022-12-16T14:22:21.317662",
     "exception": false,
     "start_time": "2022-12-16T14:18:32.662062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Performing PCA and keeping the 500 biggest components\n",
    "pca = PCA(n_components=500)\n",
    "principalComponents = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06c717ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:22:21.388803Z",
     "iopub.status.busy": "2022-12-16T14:22:21.388273Z",
     "iopub.status.idle": "2022-12-16T14:22:21.795121Z",
     "shell.execute_reply": "2022-12-16T14:22:21.793917Z"
    },
    "papermill": {
     "duration": 0.443065,
     "end_time": "2022-12-16T14:22:21.797805",
     "exception": false,
     "start_time": "2022-12-16T14:22:21.354740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating a new features dataframe using PCA and our directly-linked genes\n",
    "df_features = df_features.join(pd.DataFrame(data=principalComponents, index=df_features.index), on=\"cell_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a715410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:22:21.863146Z",
     "iopub.status.busy": "2022-12-16T14:22:21.862756Z",
     "iopub.status.idle": "2022-12-16T14:22:22.131538Z",
     "shell.execute_reply": "2022-12-16T14:22:22.130328Z"
    },
    "papermill": {
     "duration": 0.30415,
     "end_time": "2022-12-16T14:22:22.134091",
     "exception": false,
     "start_time": "2022-12-16T14:22:21.829941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimizing the RAM by removing useless variables\n",
    "del pca, df_to_pca, x, principalComponents\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd6ec10",
   "metadata": {
    "papermill": {
     "duration": 0.031171,
     "end_time": "2022-12-16T14:22:22.196491",
     "exception": false,
     "start_time": "2022-12-16T14:22:22.165320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4.4. Creating the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12242147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:22:22.262080Z",
     "iopub.status.busy": "2022-12-16T14:22:22.260958Z",
     "iopub.status.idle": "2022-12-16T14:22:22.714936Z",
     "shell.execute_reply": "2022-12-16T14:22:22.713896Z"
    },
    "papermill": {
     "duration": 0.490192,
     "end_time": "2022-12-16T14:22:22.718035",
     "exception": false,
     "start_time": "2022-12-16T14:22:22.227843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"/kaggle/input/open-problems-multimodal/metadata.csv\")#reading the metadata file \n",
    "metadata = metadata[metadata[\"cell_id\"].isin(df_features.index)].drop([\"technology\", \"donor\"], axis=1)#keeping the metadata of our citeSeq data and droping useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7745d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:22:22.782676Z",
     "iopub.status.busy": "2022-12-16T14:22:22.782279Z",
     "iopub.status.idle": "2022-12-16T14:22:23.966714Z",
     "shell.execute_reply": "2022-12-16T14:22:23.965513Z"
    },
    "papermill": {
     "duration": 1.219395,
     "end_time": "2022-12-16T14:22:23.969281",
     "exception": false,
     "start_time": "2022-12-16T14:22:22.749886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the train and test dataset based on the dates. Splting on a 80/20 split and keeping the days 2/3 and a part of day 4 on the train set and tesing on the rest.\n",
    "df_autogluon = metadata.join(df_features, on=\"cell_id\").join(df_target, on=\"cell_id\")\n",
    "df_autogluon_train_1 = df_autogluon[df_autogluon[\"day\"]<4]\n",
    "df_autogluon_day_4 = df_autogluon[df_autogluon[\"day\"]==4]\n",
    "df_autogluon_train_2 = df_autogluon_day_4.sample(n = int(df_autogluon.shape[0]*0.80 - df_autogluon_train_1.shape[0]), random_state=4)\n",
    "df_autogluon_test = df_autogluon_day_4.drop(df_autogluon_train_2.index)\n",
    "\n",
    "del df_autogluon, df_autogluon_day_4\n",
    "gc.collect()\n",
    "\n",
    "df_autogluon_train = pd.concat([df_autogluon_train_1, df_autogluon_train_2])\n",
    "\n",
    "del df_autogluon_train_1, df_autogluon_train_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1a7b3",
   "metadata": {
    "papermill": {
     "duration": 0.030575,
     "end_time": "2022-12-16T14:22:24.030879",
     "exception": false,
     "start_time": "2022-12-16T14:22:24.000304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Creation of the models using AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445d669",
   "metadata": {
    "papermill": {
     "duration": 0.030976,
     "end_time": "2022-12-16T14:22:24.093688",
     "exception": false,
     "start_time": "2022-12-16T14:22:24.062712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.1. The scoring function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57dec2b",
   "metadata": {
    "papermill": {
     "duration": 0.030713,
     "end_time": "2022-12-16T14:22:24.155963",
     "exception": false,
     "start_time": "2022-12-16T14:22:24.125250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The competition had a special metric: for every row, it computes the Pearson correlation between y_true and y_pred, and then all these correlation coefficients are averaged.\n",
    "\n",
    "In order to compare our results with other competitors, we use the same metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5a46a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:22:24.220424Z",
     "iopub.status.busy": "2022-12-16T14:22:24.219989Z",
     "iopub.status.idle": "2022-12-16T14:22:24.226853Z",
     "shell.execute_reply": "2022-12-16T14:22:24.225835Z"
    },
    "papermill": {
     "duration": 0.042209,
     "end_time": "2022-12-16T14:22:24.229134",
     "exception": false,
     "start_time": "2022-12-16T14:22:24.186925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    \"\"\"Scores the predictions according to the competition rules. \n",
    "    \n",
    "    It is assumed that the predictions are not constant.\n",
    "    \n",
    "    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c07b3",
   "metadata": {
    "papermill": {
     "duration": 0.031181,
     "end_time": "2022-12-16T14:22:24.291376",
     "exception": false,
     "start_time": "2022-12-16T14:22:24.260195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.2. Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d38d44b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T14:22:24.357337Z",
     "iopub.status.busy": "2022-12-16T14:22:24.356102Z",
     "iopub.status.idle": "2022-12-16T22:55:07.855718Z",
     "shell.execute_reply": "2022-12-16T22:55:07.853908Z"
    },
    "papermill": {
     "duration": 30763.540931,
     "end_time": "2022-12-16T22:55:07.863288",
     "exception": false,
     "start_time": "2022-12-16T14:22:24.322357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon Progress:   0%|          | 0/140 [00:00<?, ?it/s]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_142224/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_142224/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD86\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    31560.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.84s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3924\t = Validation score   (pearsonr)\n",
      "\t114.99s\t = Training   runtime\n",
      "\t1.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3924\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3898\t = Validation score   (pearsonr)\n",
      "\t88.99s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3898\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 235.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_142224/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon Progress:   1%|          | 1/140 [03:59<9:15:33, 239.81s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_142624/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_142624/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD274\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30833.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.87s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2642\t = Validation score   (pearsonr)\n",
      "\t93.3s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2642\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2609\t = Validation score   (pearsonr)\n",
      "\t81.21s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2609\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 196.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_142624/\")\n",
      "AutoGluon Progress:   1%|▏         | 2/140 [07:19<8:17:21, 216.24s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_142943/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_142943/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD270\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30702.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.85s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3236\t = Validation score   (pearsonr)\n",
      "\t55.4s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3236\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3257\t = Validation score   (pearsonr)\n",
      "\t54.28s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3257\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.58s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_142943/\")\n",
      "AutoGluon Progress:   2%|▏         | 3/140 [09:36<6:50:46, 179.90s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_143200/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_143200/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD155\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30489.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5607\t = Validation score   (pearsonr)\n",
      "\t57.94s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5607\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5766\t = Validation score   (pearsonr)\n",
      "\t57.92s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5766\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.19s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_143200/\")\n",
      "AutoGluon Progress:   3%|▎         | 4/140 [11:58<6:13:53, 164.95s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_143422/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_143422/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD112\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30334.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7775\t = Validation score   (pearsonr)\n",
      "\t263.35s\t = Training   runtime\n",
      "\t2.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7775\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7773\t = Validation score   (pearsonr)\n",
      "\t118.82s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7773\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 404.67s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_143422/\")\n",
      "AutoGluon Progress:   4%|▎         | 5/140 [18:50<9:32:00, 254.23s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_144115/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_144115/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD47\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30158.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t5.0s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6995\t = Validation score   (pearsonr)\n",
      "\t236.56s\t = Training   runtime\n",
      "\t2.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6995\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "E1216 14:45:29.825812351    1463 chttp2_transport.cc:1103]   Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\t0.6995\t = Validation score   (pearsonr)\n",
      "\t116.66s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6995\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 377.78s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_144115/\")\n",
      "AutoGluon Progress:   4%|▍         | 6/140 [25:13<11:05:35, 298.02s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_144738/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_144738/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD48\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30004.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8418\t = Validation score   (pearsonr)\n",
      "\t368.99s\t = Training   runtime\n",
      "\t3.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8418\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8426\t = Validation score   (pearsonr)\n",
      "\t121.93s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8426\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 515.18s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_144738/\")\n",
      "AutoGluon Progress:   5%|▌         | 7/140 [33:58<13:45:08, 372.24s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_145623/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_145623/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD40\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29818.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3723\t = Validation score   (pearsonr)\n",
      "\t154.22s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3723\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3758\t = Validation score   (pearsonr)\n",
      "\t98.18s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3758\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 274.29s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_145623/\")\n",
      "AutoGluon Progress:   6%|▌         | 8/140 [38:39<12:34:46, 343.08s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_150103/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_150103/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD154\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29605.5 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3705\t = Validation score   (pearsonr)\n",
      "\t60.9s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3705\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3724\t = Validation score   (pearsonr)\n",
      "\t56.33s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3724\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.38s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_150103/\")\n",
      "AutoGluon Progress:   6%|▋         | 9/140 [41:04<10:13:31, 281.01s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_150328/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_150328/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD52\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29439.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.94s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4543\t = Validation score   (pearsonr)\n",
      "\t54.9s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4543\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4594\t = Validation score   (pearsonr)\n",
      "\t54.96s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4594\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.5s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_150328/\")\n",
      "AutoGluon Progress:   7%|▋         | 10/140 [43:20<8:32:05, 236.35s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_150544/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_150544/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD3\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29297.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.87s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0928\t = Validation score   (pearsonr)\n",
      "\t50.32s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0928\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0849\t = Validation score   (pearsonr)\n",
      "\t52.52s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0849\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 124.64s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_150544/\")\n",
      "AutoGluon Progress:   8%|▊         | 11/140 [45:27<7:16:19, 202.94s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_150751/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_150751/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD8\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29095.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.5s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.81s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1529\t = Validation score   (pearsonr)\n",
      "\t73.35s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1529\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1387\t = Validation score   (pearsonr)\n",
      "\t91.35s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1387\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 186.3s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_150751/\")\n",
      "AutoGluon Progress:   9%|▊         | 12/140 [48:36<7:03:49, 198.67s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_151100/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_151100/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD56\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    28946.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1668\t = Validation score   (pearsonr)\n",
      "\t50.68s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1668\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1522\t = Validation score   (pearsonr)\n",
      "\t50.65s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1522\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 123.05s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_151100/\")\n",
      "AutoGluon Progress:   9%|▉         | 13/140 [50:41<6:13:30, 176.46s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_151306/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_151306/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD19\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    28749.3 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.87s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3201\t = Validation score   (pearsonr)\n",
      "\t49.95s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3201\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3152\t = Validation score   (pearsonr)\n",
      "\t49.76s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3152\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 121.48s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_151306/\")\n",
      "AutoGluon Progress:  10%|█         | 14/140 [52:45<5:37:17, 160.61s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_151510/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_151510/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD33\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    28561.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6729\t = Validation score   (pearsonr)\n",
      "\t242.4s\t = Training   runtime\n",
      "\t2.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6729\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6726\t = Validation score   (pearsonr)\n",
      "\t87.07s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6726\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 351.83s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_151510/\")\n",
      "AutoGluon Progress:  11%|█         | 15/140 [58:42<7:37:44, 219.72s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_152106/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_152106/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD11c\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    28414.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4698\t = Validation score   (pearsonr)\n",
      "\t136.96s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4698\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4705\t = Validation score   (pearsonr)\n",
      "\t95.88s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4705\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 254.66s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_152106/\")\n",
      "AutoGluon Progress:  11%|█▏        | 16/140 [1:03:03<7:59:48, 232.16s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_152527/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_152527/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: HLA-A-B-C\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    28221.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.92s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6937\t = Validation score   (pearsonr)\n",
      "\t240.65s\t = Training   runtime\n",
      "\t2.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6937\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6922\t = Validation score   (pearsonr)\n",
      "\t98.14s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6922\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 361.71s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_152527/\")\n",
      "AutoGluon Progress:  12%|█▏        | 17/140 [1:09:10<9:18:56, 272.65s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_153134/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_153134/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD45RA\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    28061.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8081\t = Validation score   (pearsonr)\n",
      "\t342.16s\t = Training   runtime\n",
      "\t3.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8081\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8118\t = Validation score   (pearsonr)\n",
      "\t119.59s\t = Training   runtime\n",
      "\t1.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8118\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 484.95s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_153134/\")\n",
      "AutoGluon Progress:  13%|█▎        | 18/140 [1:17:25<11:30:08, 339.42s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_153949/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_153949/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD123\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27903.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.576\t = Validation score   (pearsonr)\n",
      "\t58.2s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.576\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5852\t = Validation score   (pearsonr)\n",
      "\t58.0s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5852\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.81s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_153949/\")\n",
      "AutoGluon Progress:  14%|█▎        | 19/140 [1:19:48<9:25:31, 280.42s/it] No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_154212/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_154212/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD7\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27726.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2399\t = Validation score   (pearsonr)\n",
      "\t74.99s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2399\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2305\t = Validation score   (pearsonr)\n",
      "\t70.07s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2305\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 166.87s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_154212/\")\n",
      "AutoGluon Progress:  14%|█▍        | 20/140 [1:22:37<8:14:14, 247.12s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_154502/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_154502/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD105\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27533.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3124\t = Validation score   (pearsonr)\n",
      "\t56.03s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3124\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3136\t = Validation score   (pearsonr)\n",
      "\t54.92s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3136\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 132.79s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_154502/\")\n",
      "AutoGluon Progress:  15%|█▌        | 21/140 [1:24:56<7:05:22, 214.47s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_154720/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_154720/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49f\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27371.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.659\t = Validation score   (pearsonr)\n",
      "\t58.86s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.659\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7731\t = Validation score   (pearsonr)\n",
      "\t339.24s\t = Training   runtime\n",
      "\t2.95s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7731\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 420.83s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_154720/\")\n",
      "AutoGluon Progress:  16%|█▌        | 22/140 [1:32:06<9:09:06, 279.21s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_155430/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_155430/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD194\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27196.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0415\t = Validation score   (pearsonr)\n",
      "\t48.65s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0415\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0454\t = Validation score   (pearsonr)\n",
      "\t59.33s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0454\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 135.25s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_155430/\")\n",
      "AutoGluon Progress:  16%|█▋        | 23/140 [1:34:26<7:43:21, 237.62s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_155651/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_155651/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD4\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27013.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3058\t = Validation score   (pearsonr)\n",
      "\t55.17s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3058\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3062\t = Validation score   (pearsonr)\n",
      "\t53.13s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3062\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.87s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_155651/\")\n",
      "AutoGluon Progress:  17%|█▋        | 24/140 [1:36:43<6:40:33, 207.19s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_155907/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_155907/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD44\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    26827.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7044\t = Validation score   (pearsonr)\n",
      "\t223.93s\t = Training   runtime\n",
      "\t1.98s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7044\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7035\t = Validation score   (pearsonr)\n",
      "\t107.01s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7035\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 353.59s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_155907/\")\n",
      "AutoGluon Progress:  18%|█▊        | 25/140 [1:42:41<8:04:12, 252.63s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_160506/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_160506/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD14\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    26645.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.96s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1418\t = Validation score   (pearsonr)\n",
      "\t50.13s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1418\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1257\t = Validation score   (pearsonr)\n",
      "\t55.55s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1257\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 135.89s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_160506/\")\n",
      "AutoGluon Progress:  19%|█▊        | 26/140 [1:45:00<6:55:10, 218.51s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_160724/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_160724/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD16\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    26528.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.39s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0371\t = Validation score   (pearsonr)\n",
      "\t49.21s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0371\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0466\t = Validation score   (pearsonr)\n",
      "\t47.68s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0466\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 119.45s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_160724/\")\n",
      "AutoGluon Progress:  19%|█▉        | 27/140 [1:47:04<5:58:18, 190.25s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_160929/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_160929/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD25\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    26298.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1666\t = Validation score   (pearsonr)\n",
      "\t50.2s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1666\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1637\t = Validation score   (pearsonr)\n",
      "\t49.31s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1637\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 120.91s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_160929/\")\n",
      "AutoGluon Progress:  20%|██        | 28/140 [1:49:08<5:17:43, 170.21s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_161132/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_161132/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD45RO\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    26114.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4386\t = Validation score   (pearsonr)\n",
      "\t180.79s\t = Training   runtime\n",
      "\t1.39s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4386\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.438\t = Validation score   (pearsonr)\n",
      "\t98.19s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.438\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 300.61s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_161132/\")\n",
      "AutoGluon Progress:  21%|██        | 29/140 [1:54:12<6:29:17, 210.43s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_161637/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_161637/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD279\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25963.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t8.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 9.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3385\t = Validation score   (pearsonr)\n",
      "\t167.33s\t = Training   runtime\n",
      "\t1.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3385\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3396\t = Validation score   (pearsonr)\n",
      "\t103.39s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3396\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 304.2s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_161637/\")\n",
      "AutoGluon Progress:  21%|██▏       | 30/140 [1:59:24<7:21:19, 240.73s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_162148/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_162148/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: TIGIT\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25774.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.31s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2396\t = Validation score   (pearsonr)\n",
      "\t55.99s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2396\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2268\t = Validation score   (pearsonr)\n",
      "\t55.31s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2268\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 134.27s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_162148/\")\n",
      "AutoGluon Progress:  22%|██▏       | 31/140 [2:01:41<6:20:49, 209.62s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_162405/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_162405/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: Mouse-IgG1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25586.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2359\t = Validation score   (pearsonr)\n",
      "\t54.95s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2359\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2338\t = Validation score   (pearsonr)\n",
      "\t53.73s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2338\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.72s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_162405/\")\n",
      "AutoGluon Progress:  23%|██▎       | 32/140 [2:03:54<5:36:05, 186.71s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_162618/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_162618/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: Mouse-IgG2a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25420.5 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1639\t = Validation score   (pearsonr)\n",
      "\t84.31s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1639\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2139\t = Validation score   (pearsonr)\n",
      "\t85.86s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2139\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 192.13s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_162618/\")\n",
      "AutoGluon Progress:  24%|██▎       | 33/140 [2:07:12<5:38:56, 190.06s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_162936/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_162936/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: Mouse-IgG2b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25228.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1352\t = Validation score   (pearsonr)\n",
      "\t76.52s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1352\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1524\t = Validation score   (pearsonr)\n",
      "\t52.65s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1524\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 151.11s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_162936/\")\n",
      "AutoGluon Progress:  24%|██▍       | 34/140 [2:09:48<5:17:54, 179.95s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_163212/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_163212/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: Rat-IgG2b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    25070.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1526\t = Validation score   (pearsonr)\n",
      "\t90.17s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1526\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1518\t = Validation score   (pearsonr)\n",
      "\t74.63s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1518\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 186.88s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_163212/\")\n",
      "AutoGluon Progress:  25%|██▌       | 35/140 [2:12:58<5:20:02, 182.88s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_163522/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_163522/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD20\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24863.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2338\t = Validation score   (pearsonr)\n",
      "\t75.62s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2338\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1859\t = Validation score   (pearsonr)\n",
      "\t78.93s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1859\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 176.76s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_163522/\")\n",
      "AutoGluon Progress:  26%|██▌       | 36/140 [2:15:57<5:15:15, 181.88s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_163822/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_163822/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD335\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24743.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3783\t = Validation score   (pearsonr)\n",
      "\t56.47s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3783\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3779\t = Validation score   (pearsonr)\n",
      "\t55.16s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3779\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 133.93s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_163822/\")\n",
      "AutoGluon Progress:  26%|██▋       | 37/140 [2:18:14<4:48:48, 168.23s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_164038/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_164038/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD31\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24553.4 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7183\t = Validation score   (pearsonr)\n",
      "\t242.93s\t = Training   runtime\n",
      "\t2.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7183\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7181\t = Validation score   (pearsonr)\n",
      "\t91.54s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7181\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 356.73s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_164038/\")\n",
      "AutoGluon Progress:  27%|██▋       | 38/140 [2:24:15<6:24:38, 226.26s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_164640/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_164640/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: Podoplanin\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24401.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t5.2s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.55s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3765\t = Validation score   (pearsonr)\n",
      "\t54.75s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3765\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3804\t = Validation score   (pearsonr)\n",
      "\t54.69s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3804\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.66s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_164640/\")\n",
      "AutoGluon Progress:  28%|██▊       | 39/140 [2:26:32<5:35:44, 199.45s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_164857/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_164857/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD146\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24224.09 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0814\t = Validation score   (pearsonr)\n",
      "\t50.03s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0814\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0702\t = Validation score   (pearsonr)\n",
      "\t49.68s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0702\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 121.54s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_164857/\")\n",
      "AutoGluon Progress:  29%|██▊       | 40/140 [2:28:36<4:54:44, 176.84s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_165101/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_165101/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: IgM\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24023.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.96s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0863\t = Validation score   (pearsonr)\n",
      "\t55.15s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0863\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0923\t = Validation score   (pearsonr)\n",
      "\t50.34s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0923\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 127.11s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_165101/\")\n",
      "AutoGluon Progress:  29%|██▉       | 41/140 [2:30:49<4:29:43, 163.47s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_165313/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_165313/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD5\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23819.4 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2224\t = Validation score   (pearsonr)\n",
      "\t51.41s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2224\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.22\t = Validation score   (pearsonr)\n",
      "\t65.41s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.22\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.71s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_165313/\")\n",
      "AutoGluon Progress:  30%|███       | 42/140 [2:33:10<4:16:17, 156.91s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_165535/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_165535/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD195\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23639.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3058\t = Validation score   (pearsonr)\n",
      "\t117.56s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3058\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.308\t = Validation score   (pearsonr)\n",
      "\t80.35s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.308\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 220.68s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_165535/\")\n",
      "AutoGluon Progress:  31%|███       | 43/140 [2:36:57<4:47:45, 178.00s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_165922/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_165922/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD32\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23444.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8516\t = Validation score   (pearsonr)\n",
      "\t499.28s\t = Training   runtime\n",
      "\t4.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8516\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8521\t = Validation score   (pearsonr)\n",
      "\t96.74s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8521\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 619.95s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_165922/\")\n",
      "AutoGluon Progress:  31%|███▏      | 44/140 [2:47:30<8:22:46, 314.24s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_170954/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_170954/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD196\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23296.4 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.95s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1994\t = Validation score   (pearsonr)\n",
      "\t51.12s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1994\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2181\t = Validation score   (pearsonr)\n",
      "\t51.24s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2181\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 123.89s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_170954/\")\n",
      "AutoGluon Progress:  32%|███▏      | 45/140 [2:49:39<6:49:38, 258.72s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_171203/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_171203/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD185\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23119.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2445\t = Validation score   (pearsonr)\n",
      "\t102.65s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2445\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2449\t = Validation score   (pearsonr)\n",
      "\t96.79s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2449\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 221.7s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_171203/\")\n",
      "AutoGluon Progress:  33%|███▎      | 46/140 [2:53:27<6:30:50, 249.48s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_171551/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_171551/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD103\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22950.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3758\t = Validation score   (pearsonr)\n",
      "\t53.83s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3758\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3652\t = Validation score   (pearsonr)\n",
      "\t53.76s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3652\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.66s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_171551/\")\n",
      "AutoGluon Progress:  34%|███▎      | 47/140 [2:55:39<5:32:05, 214.26s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_171803/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_171803/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD69\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22764.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2982\t = Validation score   (pearsonr)\n",
      "\t52.24s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2982\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3119\t = Validation score   (pearsonr)\n",
      "\t51.16s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3119\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 126.04s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_171803/\")\n",
      "AutoGluon Progress:  34%|███▍      | 48/140 [2:57:50<4:50:19, 189.34s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_172014/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_172014/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD62L\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22569.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7309\t = Validation score   (pearsonr)\n",
      "\t67.04s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7309\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7354\t = Validation score   (pearsonr)\n",
      "\t61.6s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7354\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.87s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_172014/\")\n",
      "AutoGluon Progress:  35%|███▌      | 49/140 [3:00:26<4:31:57, 179.31s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_172250/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_172250/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD161\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22387.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.6s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.94s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1281\t = Validation score   (pearsonr)\n",
      "\t51.57s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1281\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1204\t = Validation score   (pearsonr)\n",
      "\t52.88s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1204\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 126.53s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_172250/\")\n",
      "AutoGluon Progress:  36%|███▌      | 50/140 [3:02:35<4:06:19, 164.22s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_172459/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_172459/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD152\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22203.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3626\t = Validation score   (pearsonr)\n",
      "\t56.27s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3626\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3601\t = Validation score   (pearsonr)\n",
      "\t56.13s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3601\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 133.94s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_172459/\")\n",
      "AutoGluon Progress:  36%|███▋      | 51/140 [3:04:51<3:51:15, 155.90s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_172716/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_172716/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD223\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    22060.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2656\t = Validation score   (pearsonr)\n",
      "\t98.87s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2656\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2602\t = Validation score   (pearsonr)\n",
      "\t95.03s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2602\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 216.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_172716/\")\n",
      "AutoGluon Progress:  37%|███▋      | 52/140 [3:08:31<4:16:40, 175.01s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_173055/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_173055/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: KLRG1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21891.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.96s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5216\t = Validation score   (pearsonr)\n",
      "\t168.9s\t = Training   runtime\n",
      "\t1.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5216\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5879\t = Validation score   (pearsonr)\n",
      "\t167.82s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5879\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 359.23s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_173055/\")\n",
      "AutoGluon Progress:  38%|███▊      | 53/140 [3:14:38<5:37:26, 232.72s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_173703/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_173703/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD27\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21714.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1405\t = Validation score   (pearsonr)\n",
      "\t80.38s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1405\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1374\t = Validation score   (pearsonr)\n",
      "\t95.22s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1374\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 198.03s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_173703/\")\n",
      "AutoGluon Progress:  39%|███▊      | 54/140 [3:17:59<5:19:49, 223.14s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_174024/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_174024/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD107a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21516.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.468\t = Validation score   (pearsonr)\n",
      "\t58.14s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.468\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4753\t = Validation score   (pearsonr)\n",
      "\t57.7s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4753\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.78s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_174024/\")\n",
      "AutoGluon Progress:  39%|███▉      | 55/140 [3:20:22<4:42:01, 199.08s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_174246/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_174246/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD95\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21319.5 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5125\t = Validation score   (pearsonr)\n",
      "\t60.47s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5125\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5241\t = Validation score   (pearsonr)\n",
      "\t59.46s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5241\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 142.52s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_174246/\")\n",
      "AutoGluon Progress:  40%|████      | 56/140 [3:22:50<4:17:08, 183.67s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_174514/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_174514/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD134\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21171.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2677\t = Validation score   (pearsonr)\n",
      "\t116.91s\t = Training   runtime\n",
      "\t1.7s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2677\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2552\t = Validation score   (pearsonr)\n",
      "\t64.7s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2552\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 205.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_174514/\")\n",
      "AutoGluon Progress:  41%|████      | 57/140 [3:26:18<4:24:24, 191.14s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_174843/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_174843/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: HLA-DR\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21004.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4209\t = Validation score   (pearsonr)\n",
      "\t179.39s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4209\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6532\t = Validation score   (pearsonr)\n",
      "\t60.68s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6532\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 262.88s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_174843/\")\n",
      "AutoGluon Progress:  41%|████▏     | 58/140 [3:30:47<4:53:10, 214.52s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_175312/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_175312/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD1c\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20820.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3165\t = Validation score   (pearsonr)\n",
      "\t102.71s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3165\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2825\t = Validation score   (pearsonr)\n",
      "\t112.99s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2825\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 238.01s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_175312/\")\n",
      "AutoGluon Progress:  42%|████▏     | 59/140 [3:34:49<5:00:24, 222.53s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_175713/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_175713/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD11b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20634.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1462\t = Validation score   (pearsonr)\n",
      "\t118.23s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1462\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1503\t = Validation score   (pearsonr)\n",
      "\t107.66s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1503\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 249.12s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_175713/\")\n",
      "AutoGluon Progress:  43%|████▎     | 60/140 [3:39:04<5:09:52, 232.41s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_180129/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_180129/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD64\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20460.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4066\t = Validation score   (pearsonr)\n",
      "\t96.92s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4066\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4034\t = Validation score   (pearsonr)\n",
      "\t85.42s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4034\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 204.88s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_180129/\")\n",
      "AutoGluon Progress:  44%|████▎     | 61/140 [3:42:32<4:56:28, 225.18s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_180457/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_180457/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD141\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20292.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4287\t = Validation score   (pearsonr)\n",
      "\t57.15s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4287\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4291\t = Validation score   (pearsonr)\n",
      "\t56.72s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4291\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 136.0s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_180457/\")\n",
      "AutoGluon Progress:  44%|████▍     | 62/140 [3:44:54<4:20:04, 200.05s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_180718/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_180718/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD1d\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    20117.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.47s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3895\t = Validation score   (pearsonr)\n",
      "\t64.53s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3895\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3879\t = Validation score   (pearsonr)\n",
      "\t57.49s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3879\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 145.54s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_180718/\")\n",
      "AutoGluon Progress:  45%|████▌     | 63/140 [3:47:22<3:56:50, 184.55s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_180947/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_180947/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD314\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19933.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2806\t = Validation score   (pearsonr)\n",
      "\t56.13s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2806\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2815\t = Validation score   (pearsonr)\n",
      "\t55.97s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2815\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 134.27s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_180947/\")\n",
      "AutoGluon Progress:  46%|████▌     | 64/140 [3:49:42<3:36:36, 171.00s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_181206/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_181206/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD35\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19760.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4127\t = Validation score   (pearsonr)\n",
      "\t81.95s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4127\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4067\t = Validation score   (pearsonr)\n",
      "\t75.92s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4067\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 179.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_181206/\")\n",
      "AutoGluon Progress:  46%|████▋     | 65/140 [3:52:44<3:38:11, 174.55s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_181509/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_181509/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD57\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19564.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.315\t = Validation score   (pearsonr)\n",
      "\t53.62s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.315\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3019\t = Validation score   (pearsonr)\n",
      "\t53.06s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3019\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_181509/\")\n",
      "AutoGluon Progress:  47%|████▋     | 66/140 [3:54:58<3:19:58, 162.14s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_181722/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_181722/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD272\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19408.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4601\t = Validation score   (pearsonr)\n",
      "\t54.56s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4601\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4511\t = Validation score   (pearsonr)\n",
      "\t53.32s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4511\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.55s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_181722/\")\n",
      "AutoGluon Progress:  48%|████▊     | 67/140 [3:57:10<3:06:17, 153.11s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_181934/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_181934/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD278\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19228.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3297\t = Validation score   (pearsonr)\n",
      "\t56.08s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3297\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3235\t = Validation score   (pearsonr)\n",
      "\t56.25s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3235\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 134.27s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_181934/\")\n",
      "AutoGluon Progress:  49%|████▊     | 68/140 [3:59:26<2:57:49, 148.18s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_182151/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_182151/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD58\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19061.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5663\t = Validation score   (pearsonr)\n",
      "\t59.09s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5663\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5831\t = Validation score   (pearsonr)\n",
      "\t58.38s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5831\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.61s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_182151/\")\n",
      "AutoGluon Progress:  49%|████▉     | 69/140 [4:01:51<2:54:09, 147.18s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_182416/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_182416/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD39\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18899.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4026\t = Validation score   (pearsonr)\n",
      "\t97.02s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4026\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4113\t = Validation score   (pearsonr)\n",
      "\t82.32s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4113\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 201.4s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_182416/\")\n",
      "AutoGluon Progress:  50%|█████     | 70/140 [4:05:19<3:12:57, 165.39s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_182743/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_182743/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CX3CR1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18701.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3557\t = Validation score   (pearsonr)\n",
      "\t183.15s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3557\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3538\t = Validation score   (pearsonr)\n",
      "\t97.15s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3538\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 303.41s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_182743/\")\n",
      "AutoGluon Progress:  51%|█████     | 71/140 [4:10:27<3:59:12, 208.01s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_183251/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_183251/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD24\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18511.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2562\t = Validation score   (pearsonr)\n",
      "\t55.16s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2562\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2697\t = Validation score   (pearsonr)\n",
      "\t59.47s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2697\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 143.48s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_183251/\")\n",
      "AutoGluon Progress:  51%|█████▏    | 72/140 [4:12:56<3:35:42, 190.33s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_183520/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_183520/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD21\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18354.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1683\t = Validation score   (pearsonr)\n",
      "\t100.23s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1683\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1635\t = Validation score   (pearsonr)\n",
      "\t88.87s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1635\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 211.86s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_183520/\")\n",
      "AutoGluon Progress:  52%|█████▏    | 73/140 [4:16:31<3:40:49, 197.75s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_183855/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_183855/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD11a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18159.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6325\t = Validation score   (pearsonr)\n",
      "\t60.12s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6325\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6503\t = Validation score   (pearsonr)\n",
      "\t61.14s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6503\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 143.54s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_183855/\")\n",
      "AutoGluon Progress:  53%|█████▎    | 74/140 [4:19:00<3:21:29, 183.18s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_184124/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_184124/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD79b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17985.2 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.2s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1981\t = Validation score   (pearsonr)\n",
      "\t52.4s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1981\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1888\t = Validation score   (pearsonr)\n",
      "\t52.7s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1888\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 127.36s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_184124/\")\n",
      "AutoGluon Progress:  54%|█████▎    | 75/140 [4:21:10<3:01:08, 167.21s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_184334/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_184334/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD244\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17804.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7537\t = Validation score   (pearsonr)\n",
      "\t241.1s\t = Training   runtime\n",
      "\t2.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7537\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7545\t = Validation score   (pearsonr)\n",
      "\t123.86s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7545\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.71s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_184334/\")\n",
      "AutoGluon Progress:  54%|█████▍    | 76/140 [4:27:46<4:11:38, 235.91s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_185010/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_185010/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD169\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17651.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.97s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1962\t = Validation score   (pearsonr)\n",
      "\t85.91s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1962\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1841\t = Validation score   (pearsonr)\n",
      "\t65.41s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1841\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 173.73s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_185010/\")\n",
      "AutoGluon Progress:  55%|█████▌    | 77/140 [4:30:43<3:49:05, 218.18s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_185307/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_185307/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: integrinB7\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17457.05 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5223\t = Validation score   (pearsonr)\n",
      "\t161.46s\t = Training   runtime\n",
      "\t1.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5223\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5201\t = Validation score   (pearsonr)\n",
      "\t84.46s\t = Training   runtime\n",
      "\t0.76s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5201\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 268.58s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_185307/\")\n",
      "AutoGluon Progress:  56%|█████▌    | 78/140 [4:35:16<4:02:21, 234.54s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_185740/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_185740/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD268\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17301.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1405\t = Validation score   (pearsonr)\n",
      "\t94.43s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1405\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1026\t = Validation score   (pearsonr)\n",
      "\t71.14s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1026\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 188.76s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_185740/\")\n",
      "AutoGluon Progress:  56%|█████▋    | 79/140 [4:38:27<3:45:22, 221.67s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_190052/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_190052/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD42b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    17098.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.367\t = Validation score   (pearsonr)\n",
      "\t65.97s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.367\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3458\t = Validation score   (pearsonr)\n",
      "\t66.48s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3458\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 154.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_190052/\")\n",
      "AutoGluon Progress:  57%|█████▋    | 80/140 [4:41:05<3:22:31, 202.52s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_190329/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_190329/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD54\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16924.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6407\t = Validation score   (pearsonr)\n",
      "\t206.05s\t = Training   runtime\n",
      "\t1.7s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6407\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6393\t = Validation score   (pearsonr)\n",
      "\t98.01s\t = Training   runtime\n",
      "\t0.92s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6393\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 326.66s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_190329/\")\n",
      "AutoGluon Progress:  58%|█████▊    | 81/140 [4:46:36<3:57:02, 241.06s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_190900/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_190900/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD62P\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16752.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.421\t = Validation score   (pearsonr)\n",
      "\t86.38s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.421\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.415\t = Validation score   (pearsonr)\n",
      "\t97.91s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.415\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 206.24s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_190900/\")\n",
      "AutoGluon Progress:  59%|█████▊    | 82/140 [4:50:06<3:43:54, 231.63s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_191230/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_191230/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD119\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16569.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.99s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.421\t = Validation score   (pearsonr)\n",
      "\t58.14s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.421\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4282\t = Validation score   (pearsonr)\n",
      "\t56.06s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4282\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 136.3s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_191230/\")\n",
      "AutoGluon Progress:  59%|█████▉    | 83/140 [4:52:32<3:15:40, 205.98s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_191456/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_191456/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: TCR\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11206.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t8.3s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 8.77s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2496\t = Validation score   (pearsonr)\n",
      "\t55.13s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2496\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2473\t = Validation score   (pearsonr)\n",
      "\t54.26s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2473\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 135.88s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_191456/\")\n",
      "AutoGluon Progress:  60%|██████    | 84/140 [4:54:50<2:53:20, 185.72s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_191715/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_191715/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: Rat-IgG1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16203.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1091\t = Validation score   (pearsonr)\n",
      "\t51.07s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1091\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1135\t = Validation score   (pearsonr)\n",
      "\t55.2s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1135\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 128.73s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_191715/\")\n",
      "AutoGluon Progress:  61%|██████    | 85/140 [4:57:04<2:35:58, 170.16s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_191928/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_191928/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: Rat-IgG2a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16021.0 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1485\t = Validation score   (pearsonr)\n",
      "\t52.43s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1485\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1444\t = Validation score   (pearsonr)\n",
      "\t51.91s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1444\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 126.37s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_191928/\")\n",
      "AutoGluon Progress:  61%|██████▏   | 86/140 [4:59:13<2:21:59, 157.77s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_192137/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_192137/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD192\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15848.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3184\t = Validation score   (pearsonr)\n",
      "\t55.33s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3184\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3229\t = Validation score   (pearsonr)\n",
      "\t53.43s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3229\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.56s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_192137/\")\n",
      "AutoGluon Progress:  62%|██████▏   | 87/140 [5:01:29<2:13:31, 151.16s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_192353/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_192353/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD122\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15662.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1247\t = Validation score   (pearsonr)\n",
      "\t51.6s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1247\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1319\t = Validation score   (pearsonr)\n",
      "\t62.8s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1319\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 141.34s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_192353/\")\n",
      "AutoGluon Progress:  63%|██████▎   | 88/140 [5:03:55<2:09:49, 149.80s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_192620/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_192620/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: FceRIa\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15526.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6449\t = Validation score   (pearsonr)\n",
      "\t54.71s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6449\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6445\t = Validation score   (pearsonr)\n",
      "\t53.49s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6445\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_192620/\")\n",
      "AutoGluon Progress:  64%|██████▎   | 89/140 [5:06:09<2:03:12, 144.95s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_192833/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_192833/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD41\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15304.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9046\t = Validation score   (pearsonr)\n",
      "\t269.02s\t = Training   runtime\n",
      "\t2.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.9046\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.9059\t = Validation score   (pearsonr)\n",
      "\t99.78s\t = Training   runtime\n",
      "\t0.9s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.9059\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 391.56s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_192833/\")\n",
      "AutoGluon Progress:  64%|██████▍   | 90/140 [5:12:49<3:04:37, 221.56s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_193514/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_193514/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD137\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15149.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4192\t = Validation score   (pearsonr)\n",
      "\t63.24s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4192\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4207\t = Validation score   (pearsonr)\n",
      "\t57.05s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4207\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 150.17s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_193514/\")\n",
      "AutoGluon Progress:  65%|██████▌   | 91/140 [5:15:25<2:44:50, 201.84s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_193749/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_193749/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD163\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14976.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2251\t = Validation score   (pearsonr)\n",
      "\t54.46s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2251\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2205\t = Validation score   (pearsonr)\n",
      "\t54.56s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2205\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 132.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_193749/\")\n",
      "AutoGluon Progress:  66%|██████▌   | 92/140 [5:17:40<2:25:23, 181.74s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_194004/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_194004/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD83\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14813.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3673\t = Validation score   (pearsonr)\n",
      "\t113.04s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3673\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4116\t = Validation score   (pearsonr)\n",
      "\t106.27s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4116\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 242.09s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_194004/\")\n",
      "AutoGluon Progress:  66%|██████▋   | 93/140 [5:21:49<2:38:09, 201.90s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_194413/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_194413/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD124\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14619.48 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3809\t = Validation score   (pearsonr)\n",
      "\t62.69s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3809\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3774\t = Validation score   (pearsonr)\n",
      "\t67.67s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3774\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 152.89s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_194413/\")\n",
      "AutoGluon Progress:  67%|██████▋   | 94/140 [5:24:25<2:24:10, 188.06s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_194649/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_194649/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD13\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14442.28 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5669\t = Validation score   (pearsonr)\n",
      "\t141.56s\t = Training   runtime\n",
      "\t1.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5669\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6786\t = Validation score   (pearsonr)\n",
      "\t225.57s\t = Training   runtime\n",
      "\t1.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6786\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 391.11s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_194649/\")\n",
      "AutoGluon Progress:  68%|██████▊   | 95/140 [5:31:04<3:08:30, 251.35s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_195328/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_195328/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14275.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.23\t = Validation score   (pearsonr)\n",
      "\t92.05s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.23\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1335\t = Validation score   (pearsonr)\n",
      "\t46.77s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1335\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 161.25s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_195328/\")\n",
      "AutoGluon Progress:  69%|██████▊   | 96/140 [5:33:48<2:45:12, 225.29s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_195613/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_195613/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD226\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14097.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3195\t = Validation score   (pearsonr)\n",
      "\t53.02s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3195\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3171\t = Validation score   (pearsonr)\n",
      "\t54.04s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3171\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 128.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_195613/\")\n",
      "AutoGluon Progress:  69%|██████▉   | 97/140 [5:36:00<2:21:16, 197.13s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_195824/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_195824/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD29\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13906.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.97s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6273\t = Validation score   (pearsonr)\n",
      "\t59.86s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6273\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6453\t = Validation score   (pearsonr)\n",
      "\t59.92s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6453\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 141.5s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_195824/\")\n",
      "AutoGluon Progress:  70%|███████   | 98/140 [5:38:27<2:07:28, 182.11s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_200051/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_200051/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD303\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13743.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2344\t = Validation score   (pearsonr)\n",
      "\t82.93s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2344\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2324\t = Validation score   (pearsonr)\n",
      "\t86.5s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2324\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 191.82s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_200051/\")\n",
      "AutoGluon Progress:  71%|███████   | 99/140 [5:41:41<2:07:02, 185.92s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_200406/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_200406/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13572.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8071\t = Validation score   (pearsonr)\n",
      "\t274.77s\t = Training   runtime\n",
      "\t2.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8071\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8052\t = Validation score   (pearsonr)\n",
      "\t111.28s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8052\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 408.77s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_200406/\")\n",
      "AutoGluon Progress:  71%|███████▏  | 100/140 [5:48:36<2:49:42, 254.56s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_201101/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_201101/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD81\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13375.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7408\t = Validation score   (pearsonr)\n",
      "\t308.17s\t = Training   runtime\n",
      "\t2.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7408\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.741\t = Validation score   (pearsonr)\n",
      "\t90.18s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.741\t = Validation score   (pearsonr)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 421.63s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_201101/\")\n",
      "AutoGluon Progress:  72%|███████▏  | 101/140 [5:55:47<3:19:53, 307.52s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_201812/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_201812/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: IgD\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13201.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0596\t = Validation score   (pearsonr)\n",
      "\t62.59s\t = Training   runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0596\t = Validation score   (pearsonr)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0844\t = Validation score   (pearsonr)\n",
      "\t49.71s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.0844\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.86s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_201812/\")\n",
      "AutoGluon Progress:  73%|███████▎  | 102/140 [5:58:12<2:43:45, 258.57s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_202036/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_202036/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD18\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13058.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5331\t = Validation score   (pearsonr)\n",
      "\t211.5s\t = Training   runtime\n",
      "\t1.87s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5331\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5288\t = Validation score   (pearsonr)\n",
      "\t95.41s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5288\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 329.74s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_202036/\")\n",
      "AutoGluon Progress:  74%|███████▎  | 103/140 [6:03:46<2:53:26, 281.26s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_202610/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_202610/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD28\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12874.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3167\t = Validation score   (pearsonr)\n",
      "\t53.36s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3167\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3162\t = Validation score   (pearsonr)\n",
      "\t55.04s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3162\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.56s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_202610/\")\n",
      "AutoGluon Progress:  74%|███████▍  | 104/140 [6:05:59<2:22:06, 236.85s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_202823/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_202823/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD38\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12680.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7397\t = Validation score   (pearsonr)\n",
      "\t343.04s\t = Training   runtime\n",
      "\t3.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7397\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7388\t = Validation score   (pearsonr)\n",
      "\t106.1s\t = Training   runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7388\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 473.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_202823/\")\n",
      "AutoGluon Progress:  75%|███████▌  | 105/140 [6:13:59<3:00:46, 309.90s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_203624/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_203624/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD127\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12514.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t5.0s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1928\t = Validation score   (pearsonr)\n",
      "\t53.1s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1928\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1993\t = Validation score   (pearsonr)\n",
      "\t52.7s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1993\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 128.7s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_203624/\")\n",
      "AutoGluon Progress:  76%|███████▌  | 106/140 [6:16:13<2:25:42, 257.13s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_203838/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_203838/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD45\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12313.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4045\t = Validation score   (pearsonr)\n",
      "\t149.3s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4045\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5426\t = Validation score   (pearsonr)\n",
      "\t307.13s\t = Training   runtime\n",
      "\t1.86s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5426\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 480.11s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_203838/\")\n",
      "AutoGluon Progress:  76%|███████▋  | 107/140 [6:24:22<2:59:33, 326.47s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_204646/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_204646/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD22\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12132.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.96s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2918\t = Validation score   (pearsonr)\n",
      "\t54.48s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2918\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2789\t = Validation score   (pearsonr)\n",
      "\t55.03s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2789\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 136.45s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_204646/\")\n",
      "AutoGluon Progress:  77%|███████▋  | 108/140 [6:26:41<2:24:09, 270.31s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_204905/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_204905/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD71\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11991.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t5.0s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8525\t = Validation score   (pearsonr)\n",
      "\t569.35s\t = Training   runtime\n",
      "\t6.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8525\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8539\t = Validation score   (pearsonr)\n",
      "\t118.71s\t = Training   runtime\n",
      "\t1.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8539\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 712.52s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_204905/\")\n",
      "AutoGluon Progress:  78%|███████▊  | 109/140 [6:38:49<3:30:38, 407.71s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_210114/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_210114/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD26\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11800.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5945\t = Validation score   (pearsonr)\n",
      "\t112.9s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5945\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5908\t = Validation score   (pearsonr)\n",
      "\t91.1s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5908\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 235.75s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_210114/\")\n",
      "AutoGluon Progress:  79%|███████▊  | 110/140 [6:42:49<2:58:37, 357.24s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_210513/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_210513/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD115\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11593.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.65\t = Validation score   (pearsonr)\n",
      "\t56.24s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.65\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.655\t = Validation score   (pearsonr)\n",
      "\t54.79s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.655\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 139.19s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_210513/\")\n",
      "AutoGluon Progress:  79%|███████▉  | 111/140 [6:45:13<2:21:47, 293.37s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_210737/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_210737/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD63\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11454.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.557\t = Validation score   (pearsonr)\n",
      "\t58.35s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.557\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5845\t = Validation score   (pearsonr)\n",
      "\t59.14s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5845\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 140.3s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_210737/\")\n",
      "AutoGluon Progress:  80%|████████  | 112/140 [6:47:39<1:56:12, 249.03s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_211003/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_211003/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD304\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11236.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5401\t = Validation score   (pearsonr)\n",
      "\t92.22s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5401\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5521\t = Validation score   (pearsonr)\n",
      "\t116.51s\t = Training   runtime\n",
      "\t1.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5521\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 231.07s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_211003/\")\n",
      "AutoGluon Progress:  81%|████████  | 113/140 [6:51:36<1:50:30, 245.58s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_211401/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_211401/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD36\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11061.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t5.1s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8446\t = Validation score   (pearsonr)\n",
      "\t293.48s\t = Training   runtime\n",
      "\t2.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8446\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8408\t = Validation score   (pearsonr)\n",
      "\t103.63s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8408\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 420.44s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_211401/\")\n",
      "AutoGluon Progress:  81%|████████▏ | 114/140 [6:58:42<2:09:52, 299.73s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_212107/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_212107/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD172a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10890.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2444\t = Validation score   (pearsonr)\n",
      "\t83.83s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2444\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2396\t = Validation score   (pearsonr)\n",
      "\t79.23s\t = Training   runtime\n",
      "\t0.84s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2396\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 185.02s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_212107/\")\n",
      "AutoGluon Progress:  82%|████████▏ | 115/140 [7:01:50<1:50:56, 266.27s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_212415/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_212415/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD72\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10711.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.509\t = Validation score   (pearsonr)\n",
      "\t227.95s\t = Training   runtime\n",
      "\t1.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.509\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4996\t = Validation score   (pearsonr)\n",
      "\t95.29s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4996\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 346.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_212415/\")\n",
      "AutoGluon Progress:  83%|████████▎ | 116/140 [7:07:41<1:56:40, 291.70s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_213006/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_213006/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10545.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6359\t = Validation score   (pearsonr)\n",
      "\t192.18s\t = Training   runtime\n",
      "\t1.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6359\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6322\t = Validation score   (pearsonr)\n",
      "\t106.89s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6322\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 322.46s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_213006/\")\n",
      "AutoGluon Progress:  84%|████████▎ | 117/140 [7:13:08<1:55:51, 302.25s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_213533/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_213533/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD93\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10397.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2642\t = Validation score   (pearsonr)\n",
      "\t82.19s\t = Training   runtime\n",
      "\t0.88s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2642\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2583\t = Validation score   (pearsonr)\n",
      "\t75.13s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2583\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 179.78s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_213533/\")\n",
      "AutoGluon Progress:  84%|████████▍ | 118/140 [7:16:11<1:37:40, 266.40s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_213835/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_213835/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49a\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10218.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.291\t = Validation score   (pearsonr)\n",
      "\t96.89s\t = Training   runtime\n",
      "\t0.95s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.291\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2843\t = Validation score   (pearsonr)\n",
      "\t79.61s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2843\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 198.83s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_213835/\")\n",
      "AutoGluon Progress:  85%|████████▌ | 119/140 [7:19:33<1:26:30, 247.19s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_214158/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_214158/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD49d\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10032.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5636\t = Validation score   (pearsonr)\n",
      "\t59.55s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5636\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5784\t = Validation score   (pearsonr)\n",
      "\t69.46s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5784\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 151.4s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_214158/\")\n",
      "AutoGluon Progress:  86%|████████▌ | 120/140 [7:22:10<1:13:19, 219.97s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_214434/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_214434/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD73\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9802.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t5.0s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.34s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2112\t = Validation score   (pearsonr)\n",
      "\t54.23s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2112\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1919\t = Validation score   (pearsonr)\n",
      "\t52.65s\t = Training   runtime\n",
      "\t0.65s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1919\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.66s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_214434/\")\n",
      "AutoGluon Progress:  86%|████████▋ | 121/140 [7:24:22<1:01:18, 193.62s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_214646/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_214646/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD9\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9661.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.96s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7181\t = Validation score   (pearsonr)\n",
      "\t207.23s\t = Training   runtime\n",
      "\t2.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7181\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7171\t = Validation score   (pearsonr)\n",
      "\t102.77s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7171\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 332.42s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_214646/\")\n",
      "AutoGluon Progress:  87%|████████▋ | 122/140 [7:29:59<1:10:59, 236.62s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_215223/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_215223/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVa7.2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9465.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.98s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0794\t = Validation score   (pearsonr)\n",
      "\t49.86s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0794\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.074\t = Validation score   (pearsonr)\n",
      "\t48.27s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.074\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 120.3s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_215223/\")\n",
      "AutoGluon Progress:  88%|████████▊ | 123/140 [7:32:02<57:23, 202.53s/it]  No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_215426/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_215426/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: TCRVd2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9293.07 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.5% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.02s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.0442\t = Validation score   (pearsonr)\n",
      "\t46.8s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.0442\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.037\t = Validation score   (pearsonr)\n",
      "\t53.37s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.037\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 122.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_215426/\")\n",
      "AutoGluon Progress:  89%|████████▊ | 124/140 [7:34:07<47:48, 179.28s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_215631/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_215631/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: LOX-1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    9121.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.295\t = Validation score   (pearsonr)\n",
      "\t55.28s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.295\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2974\t = Validation score   (pearsonr)\n",
      "\t54.22s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2974\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 132.27s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_215631/\")\n",
      "AutoGluon Progress:  89%|████████▉ | 125/140 [7:36:25<41:43, 166.90s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_215849/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_215849/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158b\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8950.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2646\t = Validation score   (pearsonr)\n",
      "\t53.45s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2646\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2693\t = Validation score   (pearsonr)\n",
      "\t55.42s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2693\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.72s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_215849/\")\n",
      "AutoGluon Progress:  90%|█████████ | 126/140 [7:38:49<37:20, 160.06s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_220114/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_220114/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD158e1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8797.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1156\t = Validation score   (pearsonr)\n",
      "\t52.36s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1156\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1247\t = Validation score   (pearsonr)\n",
      "\t50.39s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1247\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 125.34s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_220114/\")\n",
      "AutoGluon Progress:  91%|█████████ | 127/140 [7:41:00<32:46, 151.25s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_220324/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_220324/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD142\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8592.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4412\t = Validation score   (pearsonr)\n",
      "\t52.61s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4412\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4431\t = Validation score   (pearsonr)\n",
      "\t51.43s\t = Training   runtime\n",
      "\t0.58s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4431\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 126.31s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_220324/\")\n",
      "AutoGluon Progress:  91%|█████████▏| 128/140 [7:43:11<29:04, 145.36s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_220536/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_220536/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD319\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8441.37 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.25s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.137\t = Validation score   (pearsonr)\n",
      "\t76.04s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.137\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1674\t = Validation score   (pearsonr)\n",
      "\t89.76s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1674\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 188.27s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_220536/\")\n",
      "AutoGluon Progress:  92%|█████████▏| 129/140 [7:46:26<29:19, 159.99s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_220850/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_220850/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD352\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8250.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.7% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2886\t = Validation score   (pearsonr)\n",
      "\t129.94s\t = Training   runtime\n",
      "\t1.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2886\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2784\t = Validation score   (pearsonr)\n",
      "\t86.73s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.2784\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 239.56s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_220850/\")\n",
      "AutoGluon Progress:  93%|█████████▎| 130/140 [7:50:29<30:50, 185.06s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_221254/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_221254/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD94\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8070.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1828\t = Validation score   (pearsonr)\n",
      "\t53.51s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1828\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.1826\t = Validation score   (pearsonr)\n",
      "\t53.45s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.1826\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_221254/\")\n",
      "AutoGluon Progress:  94%|█████████▎| 131/140 [7:52:41<25:21, 169.08s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_221505/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_221505/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD162\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7893.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.8% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6431\t = Validation score   (pearsonr)\n",
      "\t214.23s\t = Training   runtime\n",
      "\t2.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6431\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.6422\t = Validation score   (pearsonr)\n",
      "\t98.13s\t = Training   runtime\n",
      "\t0.89s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.6422\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 335.01s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_221505/\")\n",
      "AutoGluon Progress:  94%|█████████▍| 132/140 [7:58:21<29:22, 220.36s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_222045/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_222045/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD85j\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7697.62 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3938\t = Validation score   (pearsonr)\n",
      "\t54.02s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3938\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3899\t = Validation score   (pearsonr)\n",
      "\t53.93s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3899\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 129.64s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_222045/\")\n",
      "AutoGluon Progress:  95%|█████████▌| 133/140 [8:00:34<22:38, 194.07s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_222258/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_222258/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD23\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7527.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.2582\t = Validation score   (pearsonr)\n",
      "\t55.46s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.2582\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.261\t = Validation score   (pearsonr)\n",
      "\t54.74s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.261\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 132.32s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_222258/\")\n",
      "AutoGluon Progress:  96%|█████████▌| 134/140 [8:02:51<17:43, 177.18s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_222516/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_222516/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD328\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7350.12 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (1.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.53\t = Validation score   (pearsonr)\n",
      "\t78.58s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.53\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5397\t = Validation score   (pearsonr)\n",
      "\t70.7s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5397\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 171.38s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_222516/\")\n",
      "AutoGluon Progress:  96%|█████████▋| 135/140 [8:05:49<14:45, 177.18s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_222813/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_222813/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: HLA-E\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7183.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (2.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (1.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3067\t = Validation score   (pearsonr)\n",
      "\t54.13s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3067\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.3137\t = Validation score   (pearsonr)\n",
      "\t53.94s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.3137\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 130.27s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_222813/\")\n",
      "AutoGluon Progress:  97%|█████████▋| 136/140 [8:08:04<10:59, 164.79s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_223029/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_223029/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD82\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7006.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (2.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (2.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7546\t = Validation score   (pearsonr)\n",
      "\t307.7s\t = Training   runtime\n",
      "\t3.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7546\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7543\t = Validation score   (pearsonr)\n",
      "\t123.2s\t = Training   runtime\n",
      "\t1.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.7543\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 453.75s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_223029/\")\n",
      "AutoGluon Progress:  98%|█████████▊| 137/140 [8:15:44<12:39, 253.32s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_223809/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_223809/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD101\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6842.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (2.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (2.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.17s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4354\t = Validation score   (pearsonr)\n",
      "\t89.45s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4354\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.4104\t = Validation score   (pearsonr)\n",
      "\t84.15s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.4104\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 195.65s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_223809/\")\n",
      "AutoGluon Progress:  99%|█████████▊| 138/140 [8:19:03<07:53, 236.91s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_224127/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_224127/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD88\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6635.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (2.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.8s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (2.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.7225\t = Validation score   (pearsonr)\n",
      "\t206.82s\t = Training   runtime\n",
      "\t1.65s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.7225\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.8191\t = Validation score   (pearsonr)\n",
      "\t256.67s\t = Training   runtime\n",
      "\t2.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.8191\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 486.64s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_224127/\")\n",
      "AutoGluon Progress:  99%|█████████▉| 139/140 [8:27:19<05:14, 314.66s/it]No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_224943/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=4, num_bag_sets=1\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (56790 samples, 143.36 MB).\n",
      "\tConsider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_224943/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Dec 10 10:12:26 UTC 2022\n",
      "Train Data Rows:    56790\n",
      "Train Data Columns: 614\n",
      "Label Column: CD224\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6480.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 142.68 MB (2.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t\t('object', []) :   1 | ['cell_type']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :   1 | ['cell_type']\n",
      "\t\t('float', [])    : 613 | ['ENSG00000002586_CD99', 'ENSG00000004468_CD38', 'ENSG00000007312_CD79B', 'ENSG00000010278_CD9', 'ENSG00000010610_CD4', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t614 features in original data used to generate 614 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 139.31 MB (2.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'pearsonr'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5837\t = Validation score   (pearsonr)\n",
      "\t174.46s\t = Training   runtime\n",
      "\t1.73s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.5837\t = Validation score   (pearsonr)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 4 child models (S1F1 - S1F4) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t0.5826\t = Validation score   (pearsonr)\n",
      "\t108.01s\t = Training   runtime\n",
      "\t0.96s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t0.5826\t = Validation score   (pearsonr)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 305.19s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_224943/\")\n",
      "AutoGluon Progress: 100%|██████████| 140/140 [8:32:29<00:00, 219.64s/it]\n"
     ]
    }
   ],
   "source": [
    "predicator_list = []\n",
    "\n",
    "#Creating model with LightGBM and XGBoost\n",
    "hyperparameters = {\n",
    "    'GBM': [\n",
    "        {}\n",
    "    ]\n",
    "}\n",
    "\n",
    "train_va = []\n",
    "test_va = []\n",
    "\n",
    "train_preds = []\n",
    "test_preds = []\n",
    "\n",
    "for i in tqdm(range(df_target.shape[1]), desc=\"AutoGluon Progress\"):\n",
    "    predicator = TabularPredictor(label=df_target.columns[i], problem_type=\"regression\", eval_metric=\"pearsonr\")\n",
    "    df_train = df_autogluon_train[df_features.columns.tolist()+[\"cell_type\"]+[df_target.columns[i]]]\n",
    "    df_test = df_autogluon_test[df_features.columns.tolist()+[\"cell_type\"]+[df_target.columns[i]]]\n",
    "    predicator.fit(df_train, presets='best_quality', hyperparameters=hyperparameters, num_bag_folds=4)\n",
    "    train_va.append(df_train[df_target.columns[i]])\n",
    "    test_va.append(df_test[df_target.columns[i]])\n",
    "    train_preds.append(predicator.predict(df_train))\n",
    "    test_preds.append(predicator.predict(df_test))\n",
    "    predicator_list.append(predicator)\n",
    "\n",
    "y_train_va = np.column_stack(train_va)\n",
    "y_test_va = np.column_stack(test_va)\n",
    "    \n",
    "y_train_pred = np.column_stack(train_preds) #concatenate the 140 train predictions\n",
    "y_test_pred = np.column_stack(test_preds) #concatenate the 140 test predictions\n",
    "\n",
    "del train_va, test_va, train_preds, test_preds, df_train, df_test\n",
    "gc.collect()\n",
    "\n",
    "mse_train = mean_squared_error(y_train_va, y_train_pred)\n",
    "corrscore_train = correlation_score(y_train_va, y_train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test_va, y_test_pred)\n",
    "corrscore_test = correlation_score(y_test_va, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d376c3",
   "metadata": {
    "papermill": {
     "duration": 0.971141,
     "end_time": "2022-12-16T22:55:10.106192",
     "exception": false,
     "start_time": "2022-12-16T22:55:09.135051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5.3. Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96139b58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-16T22:55:11.515221Z",
     "iopub.status.busy": "2022-12-16T22:55:11.514695Z",
     "iopub.status.idle": "2022-12-16T22:55:11.522429Z",
     "shell.execute_reply": "2022-12-16T22:55:11.521276Z"
    },
    "papermill": {
     "duration": 0.655183,
     "end_time": "2022-12-16T22:55:11.524723",
     "exception": false,
     "start_time": "2022-12-16T22:55:10.869540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE train is: 2.440716\n",
      "The correlation score train is: 0.8958453300448254\n",
      "The MSE test is: 2.875149\n",
      "The correlation score test is: 0.8697478587270149\n"
     ]
    }
   ],
   "source": [
    "print(\"The MSE train is:\", mse_train)\n",
    "print(\"The correlation score train is:\", corrscore_train)\n",
    "print(\"The MSE test is:\", mse_test)\n",
    "print(\"The correlation score test is:\", corrscore_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31242.135068,
   "end_time": "2022-12-16T22:55:17.462381",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-16T14:14:35.327313",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
